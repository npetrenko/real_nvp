{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean std: [0.00997741 1.20220203 0.00878533 0.04104758 0.00997741 1.20220203\n",
      " 0.00878533 0.04104758]\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "Global output:  Tensor(\"global_inf/flow_7/add_3:0\", shape=(1024, 36), dtype=float32, device=/device:CPU:0)\n",
      "Global logdens:  Tensor(\"global_inf/sub:0\", shape=(1024,), dtype=float32, device=/device:CPU:0)\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "ldiag logdens Tensor(\"AUS_model/rw_priors/PWalk_inf/flows/sub_1:0\", shape=(1024,), dtype=float32, device=/device:CPU:0)\n",
      "<dtype: 'float32'>\n",
      "Tensor(\"AUS_model/PWalk_prior/target:0\", shape=(1024, ?, 36), dtype=float32, device=/device:CPU:0)\n",
      "<dtype: 'float64'>\n",
      "<dtype: 'float32'>\n",
      "Init_distr.mu is not None\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "Noise sample: Tensor(\"AUS_model/transpose_2:0\", shape=(201, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "preds Tensor(\"AUS_model/strided_slice_7:0\", shape=(201, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Noise sample: Tensor(\"AUS_model/transpose_5:0\", shape=(201, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"AUS_model/strided_slice_12:0\", shape=(?, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"AUS_model/loglikelihood/sub:0\", shape=(?, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Diffs : Tensor(\"AUS_model/loglikelihood/sub:0\", shape=(?, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Diffs : Tensor(\"AUS_model/loglikelihood/Mean_2:0\", shape=(?, 1, 4), dtype=float32, device=/device:CPU:0)\n",
      "<dtype: 'float32'>\n",
      "\n",
      "\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "ldiag logdens Tensor(\"FRA_model/rw_priors/PWalk_inf/flows/sub_1:0\", shape=(1024,), dtype=float32, device=/device:CPU:0)\n",
      "<dtype: 'float32'>\n",
      "Tensor(\"FRA_model/PWalk_prior/target:0\", shape=(1024, ?, 36), dtype=float32, device=/device:CPU:0)\n",
      "<dtype: 'float64'>\n",
      "<dtype: 'float32'>\n",
      "Init_distr.mu is not None\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "Noise sample: Tensor(\"FRA_model/transpose_2:0\", shape=(193, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "preds Tensor(\"FRA_model/strided_slice_7:0\", shape=(193, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Noise sample: Tensor(\"FRA_model/transpose_5:0\", shape=(193, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"FRA_model/strided_slice_12:0\", shape=(?, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"FRA_model/loglikelihood/sub:0\", shape=(?, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Diffs : Tensor(\"FRA_model/loglikelihood/sub:0\", shape=(?, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Diffs : Tensor(\"FRA_model/loglikelihood/Mean_2:0\", shape=(?, 1, 4), dtype=float32, device=/device:CPU:0)\n",
      "<dtype: 'float32'>\n",
      "\n",
      "\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "ldiag logdens Tensor(\"GBR_model/rw_priors/PWalk_inf/flows/sub_1:0\", shape=(1024,), dtype=float32, device=/device:CPU:0)\n",
      "<dtype: 'float32'>\n",
      "Tensor(\"GBR_model/PWalk_prior/target:0\", shape=(1024, ?, 36), dtype=float32, device=/device:CPU:0)\n",
      "<dtype: 'float64'>\n",
      "<dtype: 'float32'>\n",
      "Init_distr.mu is not None\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "Noise sample: Tensor(\"GBR_model/transpose_2:0\", shape=(161, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "preds Tensor(\"GBR_model/strided_slice_7:0\", shape=(161, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Noise sample: Tensor(\"GBR_model/transpose_5:0\", shape=(161, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"GBR_model/strided_slice_12:0\", shape=(?, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"GBR_model/loglikelihood/sub:0\", shape=(?, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Diffs : Tensor(\"GBR_model/loglikelihood/sub:0\", shape=(?, 1024, 4), dtype=float32, device=/device:CPU:0)\n",
      "Diffs : Tensor(\"GBR_model/loglikelihood/Mean_2:0\", shape=(?, 1, 4), dtype=float32, device=/device:CPU:0)\n",
      "<dtype: 'float32'>\n",
      "\n",
      "\n",
      "logdensity:  Tensor(\"AddN:0\", shape=(1024,), dtype=float32, device=/device:CPU:0)\n",
      "prior:  Tensor(\"AddN_1:0\", shape=(1024,), dtype=float32, device=/device:CPU:0)\n",
      "KL:  Tensor(\"sub:0\", shape=(1024,), dtype=float32, device=/device:CPU:0)\n",
      "INFO:tensorflow:Restoring parameters from /home/nikita/tmp/savesv/gvar_hier_fullcond1000-MP\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from flows import NormalRW, DFlow, NVPFlow, LogNormal, GVAR, phase,Normal, floatX, MVNormal, MVNormalRW, Linear, LinearChol\n",
    "from flows.models import VARmodelSV\n",
    "import flows\n",
    "from flows import parametrized as fp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.contrib.distributions import WishartCholesky\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "ccodes = ['AUS', 'FRA', 'GBR']\n",
    "datas = ['./CDATA/{}.csv'.format(x) for x in ccodes]\n",
    "\n",
    "datas = [pd.read_csv(x, index_col='VARIABLE').iloc[:,:-1] for x in datas]\n",
    "\n",
    "mean_std = 0.\n",
    "for data in datas:\n",
    "    std = np.std(data.values[:,1:] - data.values[:,:-1], axis=1)\n",
    "    mean_std = std + mean_std\n",
    "mean_std /= len(datas)\n",
    "mean_std = np.concatenate([mean_std]*2, axis=0)\n",
    "print('Mean std: {}'.format(mean_std))\n",
    "\n",
    "max_year = 0\n",
    "for i, data in enumerate(datas):\n",
    "    data = data.astype(floatX)\n",
    "    data.columns = data.columns.astype('float32')\n",
    "    \n",
    "    new_data = np.concatenate([data.values.T[1:], data.values.T[:-1]], axis=1)\n",
    "    new_data_columns = data.columns[1:]\n",
    "    new_data = pd.DataFrame(new_data.T/mean_std[:,np.newaxis], columns=new_data_columns)\n",
    "    data = new_data\n",
    "    datas[i] = data\n",
    "    max_year = max(max(data.columns), max_year)\n",
    "\n",
    "VAR_DIM = 4\n",
    "\n",
    "YEARS = [x for x in data.columns if x > 2000]\n",
    "\n",
    "country_data = {c:d for c,d in zip(ccodes, datas)}\n",
    "\n",
    "NUM_SAMPLES=1024\n",
    "\n",
    "#BUILDING the model\n",
    "with tf.device('/cpu:0'):\n",
    "    current_year = tf.placeholder(tf.float32, shape=(), name='current_year')\n",
    "    tf.summary.scalar('current_year', current_year)\n",
    "\n",
    "    with tf.variable_scope('variation_rate', dtype=floatX):\n",
    "        variation_prior = tf.distributions.Exponential(rate=3.)\n",
    "        dim_ = (VAR_DIM*2+1)*VAR_DIM\n",
    "        variation_d = fp.pLogNormal(shape=[NUM_SAMPLES, dim_], mu=math.log(0.2), sigma=-3.)\n",
    "\n",
    "        variation = variation_d.sample()\n",
    "\n",
    "        pp = tf.cast(tf.reduce_sum(variation_prior.log_prob(tf.cast(variation, tf.float32)), axis=-1), floatX)\n",
    "        tf.add_to_collection('priors', pp)\n",
    "\n",
    "        #tf.summary.histogram('variation', variation)\n",
    "        tf.summary.scalar('mean_variation', tf.reduce_mean(variation))\n",
    "\n",
    "    with tf.variable_scope('global_inf'):\n",
    "        global_inf = DFlow([NVPFlow(dim=(VAR_DIM*2+1)*VAR_DIM, name='flow_{}'.format(i), aux_vars=tf.log(variation)) for i in range(8)], \n",
    "                            init_sigma=0.01, num_samples=NUM_SAMPLES)\n",
    "\n",
    "        with tf.variable_scope('prior'):\n",
    "            pmat = np.ones([VAR_DIM, VAR_DIM*2+1], dtype=floatX)\n",
    "            pmat[:,:VAR_DIM] = 0.1\n",
    "            pmat[:,VAR_DIM:2*VAR_DIM] = 1.\n",
    "            pmat[:,-1] = 1.\n",
    "\n",
    "            global_sigma = tf.constant(pmat.reshape(-1), dtype=floatX)[tf.newaxis]\n",
    "            global_prior = Normal(None, sigma=global_sigma).logdens(global_inf.output, reduce=[-1])\n",
    "        tf.add_to_collection('priors', global_prior)\n",
    "        tf.add_to_collection('logdensities', global_inf.logdens)\n",
    "\n",
    "    print('Global output: ', global_inf.output)\n",
    "    print('Global logdens: ', global_inf.logdens)\n",
    "\n",
    "    individ_variation_prior = Normal(shape=None, sigma=variation, mu=global_inf.output, name='indiv_variation_prior')\n",
    "\n",
    "    models = []\n",
    "    indivs = {}\n",
    "\n",
    "    with tf.variable_scope(tf.get_variable_scope(), dtype=floatX, reuse=tf.AUTO_REUSE):\n",
    "        for country, data in country_data.items():\n",
    "            with tf.variable_scope(country):\n",
    "                with tf.variable_scope('individ_variation'):\n",
    "                    aux = tf.concat([global_inf.output, tf.log(variation)], axis=-1)\n",
    "                    individ_variation = DFlow([NVPFlow((VAR_DIM*2+1)*VAR_DIM, \n",
    "                                                       name='nvp_{}'.format(i), \n",
    "                                                       aux_vars=aux) for i in range(8)], init_sigma=0.01, num_samples=NUM_SAMPLES)\n",
    "\n",
    "                    ind = individ_variation.output + global_inf.output\n",
    "                indivs[country] = ind\n",
    "\n",
    "                tf.add_to_collection('logdensities', individ_variation.logdens)\n",
    "                tf.add_to_collection('priors', individ_variation_prior.logdens(ind, reduce=[-1]))\n",
    "\n",
    "            model = VARmodelSV(data, name='{}_model'.format(country), mu=ind[:, tf.newaxis], var_dim=VAR_DIM, current_year=current_year, num_samples=NUM_SAMPLES)\n",
    "            models.append(model)\n",
    "            for p in model.priors:\n",
    "                tf.add_to_collection('priors', p)\n",
    "            for l in model.logdensities:\n",
    "                tf.add_to_collection('logdensities', l)\n",
    "            print('\\n')\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    logdensity = tf.add_n(graph.get_collection('logdensities'))\n",
    "    print('logdensity: ', logdensity)\n",
    "\n",
    "    prior = tf.add_n(graph.get_collection('priors'))\n",
    "    print('prior: ', prior)\n",
    "\n",
    "    kl = logdensity - prior\n",
    "    print('KL: ', kl)\n",
    "    kl = tf.reduce_mean(kl)\n",
    "    kl /= 36*200*4\n",
    "\n",
    "\n",
    "    kls = tf.summary.scalar('KLd', kl)\n",
    "    summary = tf.summary.merge_all()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.variable_scope('build_upd') as upd_scope:\n",
    "        vs = tf.trainable_variables()\n",
    "        grads = tf.gradients(kl, vs)\n",
    "        upd = zip(grads, vs)\n",
    "        gnans = [tf.check_numerics(x, 'nan in {}'.format(x.op.name)) for x in grads if x is not None]\n",
    "        with tf.control_dependencies(gnans):\n",
    "            main_op = tf.train.AdamOptimizer(0.002).apply_gradients(upd)\n",
    "    #main_op = tf.train.AdamOptimizer(0.002).minimize(kl)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    from flows.debug import wrapper\n",
    "    #sess = wrapper(sess)\n",
    "    #init = [tf.global_variables_initializer(), tf.variables_initializer(upd_vars)]\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    writer = tf.summary.FileWriter('/home/nikita/tmp/tfdbg/SVmodel-rate3')\n",
    "\n",
    "    def validate_year(year):\n",
    "        cdic = {model.name:model for model in models}\n",
    "        preds = {model.name:[] for model in models}\n",
    "        preds_t = {model.name: model.preds for model in models}\n",
    "\n",
    "        for step in range(3):\n",
    "            preds_i = sess.run(preds_t, {current_year:year})\n",
    "            preds_i = {k:v.mean(axis=1) for k,v in preds_i.items()}\n",
    "            for k in preds.keys():\n",
    "                preds[k].append(preds_i[k][cdic[k].years > year])\n",
    "\n",
    "        mean_pred = {k:np.mean(v, axis=0) for k,v in preds.items()}\n",
    "        for c, pred in mean_pred.items():\n",
    "            pred_years = [x for x in YEARS if x > year]\n",
    "            pred = pd.DataFrame(pred.T, columns=pred_years)\n",
    "            mean_pred[c] = pred\n",
    "\n",
    "        for model in models:\n",
    "            try:\n",
    "                a = model.data_raw.loc[:,year].values[:VAR_DIM]\n",
    "            except KeyError:\n",
    "                a = np.zeros(VAR_DIM, dtype=floatX)*np.nan\n",
    "            mean_pred[model.name]['CYEAR={}'.format(year)] = a\n",
    "        return mean_pred\n",
    "\n",
    "    saver.restore(sess, '/home/nikita/tmp/savesv/gvar_hier_fullcond1000-MP')\n",
    "    #print('restoring from failsave...')\n",
    "    #saver.restore(sess, './save/failsave')\n",
    "    #print('restored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6_gpu",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
