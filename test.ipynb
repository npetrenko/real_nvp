{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "sess = tf.InteractiveSession()\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_csv('./all.csv')['content']\n",
    "names = names.apply(lambda x: x.split('\\r\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = sum(names, [])\n",
    "names = list(map(lambda x: x.strip(' ').lower(), names))\n",
    "names = list(filter(lambda x: len(x) > 0, names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13651"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = np.loadtxt('/home/nikita/tmp/Practical_RL/week7_[recap]_rnn/names', dtype=str, delimiter=';').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in the gloom. . .',\n",
       " 'that in that paleness beautys white we see;',\n",
       " 'and of the priest eftsoons gan to inquire,',\n",
       " 'the lining purple silk, with gilt stars drawn;',\n",
       " 'as i see it hardening;']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13651"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(''.join(names)+'_'))\n",
    "dic = {x:i for i,x in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistLSTM:\n",
    "    def __init__(self, dim, name='DistLSTM', reuse=None):\n",
    "        self.dim = dim\n",
    "        self.name = name\n",
    "        self.reuse = reuse\n",
    "        \n",
    "        with tf.variable_scope(self.name, reuse=reuse):\n",
    "            cells = [tf.nn.rnn_cell.LSTMCell(128, \n",
    "                                                name='cell_{}'.format(i), \n",
    "                                                activation=tf.nn.tanh) for i in range(3)]\n",
    "            self.cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "            self.post_cell = lambda x: self.dense(x, dim, name='d1')\n",
    "            self.init_dist = tf.get_variable('init_dist',[1,dim], trainable=True,\n",
    "                                             initializer=tf.random_normal_initializer(stddev=0.01, mean=0.2))\n",
    "        \n",
    "    def forward_string_lookup(self, strings, dic):\n",
    "        inp = strings\n",
    "        \n",
    "        forward_lookup = tf.py_func(lambda x: self._convert_to_ix(x, dic), [inp], tf.int64)\n",
    "        forward_lookup = tf.reshape(forward_lookup, (-1,))\n",
    "        forward_lookup = tf.nn.embedding_lookup(tf.diag(tf.ones(len(chars))), forward_lookup)\n",
    "        forward_lookup = tf.reshape(forward_lookup, [tf.shape(inp)[0], -1, len(chars)])\n",
    "        forward_lookup = tf.cast(forward_lookup, tf.float32)\n",
    "        return forward_lookup\n",
    "    \n",
    "    def dense(self, inp, dim, name='dense'):\n",
    "        with tf.variable_scope(name, initializer=tf.random_normal_initializer(stddev=0.01)):\n",
    "            W = tf.get_variable('W', [inp.shape[-1], dim])\n",
    "            b = tf.get_variable('b', [1, dim])\n",
    "            out = tf.matmul(inp, W) + b\n",
    "        return out\n",
    "    \n",
    "    def logdens(self, seq):\n",
    "        with tf.variable_scope(self.name, reuse=self.reuse):\n",
    "            batch_size, s_len = tf.shape(seq)[0], tf.shape(seq)[1]\n",
    "\n",
    "            cell = self.cell\n",
    "\n",
    "            s_t = tf.transpose(seq, [1,0,2])\n",
    "            init_state = cell.zero_state(batch_size=batch_size, dtype=tf.float32)\n",
    "\n",
    "            init = (tf.zeros([batch_size, cell.state_size[0][0]]), init_state)\n",
    "            out,_ = tf.scan(lambda prev, x: cell(x, prev[1]), s_t, initializer=init)\n",
    "            out = tf.transpose(out, [1,0,2])\n",
    "            \n",
    "            out_dim = out.shape\n",
    "            \n",
    "            out = tf.reshape(out, [-1, out_dim[-1]])\n",
    "            out = self.post_cell(out)\n",
    "            out = tf.reshape(out, [batch_size, s_len, self.dim])\n",
    "            \n",
    "            preds = out[:,:-1]\n",
    "            target = seq[:,1:]\n",
    "                        \n",
    "            init_logits = tf.tile(self.init_dist, [batch_size,1])\n",
    "            init_nll = tf.nn.softmax_cross_entropy_with_logits_v2(labels=seq[:,0], logits=init_logits)\n",
    "            init_nll = init_nll[:,tf.newaxis]\n",
    "            \n",
    "            nll = tf.nn.softmax_cross_entropy_with_logits_v2(labels=target, logits=preds)\n",
    "            nll = tf.concat([init_nll, nll], axis=1)\n",
    "            return -nll\n",
    "        \n",
    "    def sample(self):\n",
    "        with tf.variable_scope(self.name, reuse=self.reuse):\n",
    "            init_sample = tf.distributions.Multinomial(total_count=1., logits=self.init_dist).sample()\n",
    "            \n",
    "            cell = self.cell\n",
    "\n",
    "            init_state = cell.zero_state(batch_size=1, dtype=tf.float32)\n",
    "\n",
    "            init = (init_sample, init_state)\n",
    "            \n",
    "            def step(prev):\n",
    "                x = prev[0]\n",
    "                state = prev[1]\n",
    "                cell_step = cell(x, state)\n",
    "                post_step = self.post_cell(cell_step[0])\n",
    "                post_step = tf.distributions.Multinomial(total_count=1., logits=post_step).sample()\n",
    "                return post_step, cell_step[1]\n",
    "            \n",
    "            out,_ = tf.scan(lambda prev, _: step(prev), tf.range(10), initializer=init)\n",
    "            out = tf.transpose(out, [1,0,2])\n",
    "            out = tf.concat([init_sample[:,tf.newaxis,:], out], axis=1)\n",
    "            return out                \n",
    "            \n",
    "    def backward_string_lookup(self, encs, dic):\n",
    "        encs = tf.cast(encs, tf.bool)\n",
    "        strs = tf.py_func(lambda x: self._convert_from_enc(x, dic), [encs], tf.string)\n",
    "        return strs\n",
    "        \n",
    "    @staticmethod\n",
    "    def _convert_to_ix(names, dic):\n",
    "        if type(names[0]) != str:\n",
    "            names = list(map(lambda x: x.decode('utf-8'), names))\n",
    "        chars = []\n",
    "        max_len = max([len(x) for x in names])\n",
    "        filler = dic['_']\n",
    "        for name in names:\n",
    "            chars.append([])\n",
    "            for s in name:\n",
    "                chars[-1].append(dic[s])\n",
    "            chars[-1] += [filler]*(max_len-len(name))\n",
    "        return np.array(chars)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _convert_from_enc(encs, dic):\n",
    "        rev_dic = {i:x for x,i in dic.items()}\n",
    "        ret = []\n",
    "        for row in encs:\n",
    "            table = np.array([range(len(dic))]*len(row))\n",
    "            ixs = table[row]\n",
    "            chars = [rev_dic[ix] for ix in ixs]\n",
    "            string = ''.join(chars)\n",
    "            ret.append(string)\n",
    "        return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13651"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = names[:13000]\n",
    "test = names[13000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.Variable(np.array(train), trainable=False, name='train_data')\n",
    "test_data = tf.Variable(np.array(test), trainable=False, name='test_data')\n",
    "\n",
    "shuffle_op = tf.assign(train_data, tf.random_shuffle(train_data))\n",
    "train_crop = tf.random_crop(train_data, [30])\n",
    "# test_data = tf.random_crop(train_data, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlstm = DistLSTM(len(chars), reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_lk = dlstm.forward_string_lookup(train_crop, dic)\n",
    "\n",
    "fwd_lk_test = dlstm.forward_string_lookup(test_data, dic)\n",
    "\n",
    "train_loss = -tf.reduce_mean(dlstm.logdens(fwd_lk))\n",
    "\n",
    "test_loss = -tf.reduce_mean(dlstm.logdens(fwd_lk_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dlstm.sample()\n",
    "reconstr = dlstm.backward_string_lookup(sample, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -R /tmp/tfdbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sum = tf.summary.scalar('train_loss', train_loss)\n",
    "tf.summary.scalar('test_loss', test_loss)\n",
    "summary = tf.summary.merge_all()\n",
    "!mkdir /tmp/tfdbg\n",
    "writer = tf.summary.FileWriter('/tmp/tfdbg/0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer(0.001).minimize(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'j0&bu,xxiwo'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1157277\n",
      "[b'/jf_lh_ o  ']\n",
      "0.5734027\n",
      "[b\"'ts ho toy_\"]\n",
      "1.9748956\n",
      "[b\"c3ddy_' oh \"]\n",
      "2.006459\n",
      "[b'rpa,aeef th']\n",
      "1.5927196\n",
      "[b'}fd hes not']\n",
      "1.0691086\n",
      "[b'weee efich ']\n",
      "1.6127661\n",
      "[b'wtibh sorke']\n",
      "1.5318669\n",
      "[b'fid logo?__']\n",
      "1.4753472\n",
      "[b'thagh in te']\n",
      "1.3890625\n",
      "[b'to beunt il']\n",
      "1.5561079\n",
      "[b'-dsere nle ']\n",
      "0.7121343\n",
      "[b'yow it the ']\n",
      "1.037643\n",
      "[b'6oud this t']\n",
      "0.95067656\n",
      "[b'-jnes mume ']\n",
      "1.3855321\n",
      "[b\"sa'rling sh\"]\n",
      "1.2619938\n",
      "[b'and the nom']\n",
      "1.0225868\n",
      "[b'but for kea']\n",
      "1.3813763\n",
      "[b\"y've dlest \"]\n",
      "0.35452494\n",
      "[b\"and ull'r: \"]\n",
      "0.39608467\n",
      "[b'igtart cont']\n",
      "1.2318597\n",
      "[b'sgeed of pr']\n",
      "1.1482967\n",
      "[b'that we whe']\n",
      "1.3252058\n",
      "[b'whithe a ra']\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    for batch in range(200):\n",
    "        opt.run()\n",
    "        if batch % 20 == 0:\n",
    "            s = train_sum.eval()\n",
    "            writer.add_summary(s)\n",
    "\n",
    "    print(train_loss.eval())\n",
    "    s = summary.eval()\n",
    "    writer.add_summary(s)\n",
    "    shuffle_op.eval()\n",
    "    print(reconstr.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (sys p)",
   "language": "python",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
