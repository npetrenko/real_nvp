{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from flows import NormalRW, DFlow, NVPFlow, LogNormal, GVAR, phase,\\\n",
    "Normal, floatX, MVNormal, MVNormalRW, Linear, LinearChol\n",
    "import flows\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.contrib.distributions import WishartCholesky\n",
    "import math\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/test_aus_data.csv').values.astype(floatX).T[np.newaxis][:,1:]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:,1:] - data[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43681784 0.25903015 0.01298369]\n"
     ]
    }
   ],
   "source": [
    "stds = (data[0,1:] - data[0,:-1]).std(axis=0)\n",
    "print(stds)\n",
    "data /= stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.variable_scope.VariableScope object at 0x7f6f427b4748>\n",
      "<tensorflow.python.ops.variable_scope.VariableScope object at 0x7f6f426ec7f0>\n"
     ]
    }
   ],
   "source": [
    "NUM_STEPS = data.shape[1]\n",
    "\n",
    "with tf.variable_scope('walk_ord'):\n",
    "    s1_prior_d = LogNormal(1, mu=math.log(0.01), sigma=3.)\n",
    "\n",
    "    with tf.variable_scope('s1_inference', dtype=floatX):\n",
    "        mu = tf.get_variable('mu', shape=[1], initializer=tf.constant_initializer(s1_prior_d.mu))\n",
    "        logsigma = tf.get_variable('logsigma', shape=[1], \n",
    "                                   initializer=tf.constant_initializer(math.log(s1_prior_d.sigma) - 1.))\n",
    "        sigma = tf.exp(logsigma)\n",
    "        s1_d = LogNormal(1, mu=mu, sigma=sigma)\n",
    "    \n",
    "    s1 = s1_d.sample()\n",
    "    tf.summary.scalar('s1_ord', s1[0])\n",
    "    tf.add_to_collection('logdensities', s1_d.logdens(s1))\n",
    "    \n",
    "    s1_prior = s1_prior_d.logdens(s1)\n",
    "    tf.add_to_collection('priors', s1_prior)\n",
    "    \n",
    "#distribution for shock increase factor\n",
    "with tf.variable_scope('walk_shock'):\n",
    "    incr_prior_d = LogNormal(1, mu=math.log(1.), sigma=2.)\n",
    "\n",
    "    with tf.variable_scope('incr_inference', dtype=floatX):\n",
    "        mu = tf.get_variable('mu', shape=[1], initializer=tf.constant_initializer(incr_prior_d.mu))\n",
    "        logsigma = tf.get_variable('logsigma', shape=[1], \n",
    "                                   initializer=tf.constant_initializer(math.log(incr_prior_d.sigma) - 1.))\n",
    "        sigma = tf.exp(logsigma)\n",
    "        incr_d = LogNormal(1, mu=mu, sigma=sigma)\n",
    "\n",
    "    incr = incr_d.sample()\n",
    "    tf.add_to_collection('logdensities', incr_d.logdens(incr))\n",
    "    \n",
    "    incr_prior = incr_prior_d.logdens(incr)\n",
    "    tf.add_to_collection('priors', incr_prior)\n",
    "\n",
    "    incr += 1.3\n",
    "    s_shock = s1*incr\n",
    "    tf.summary.scalar('s1_shock', s_shock[0])\n",
    "    \n",
    "s0 = 80.\n",
    "dim = [3,4]\n",
    "\n",
    "K = dim[0] * dim[1]\n",
    "\n",
    "PWalk = NormalRW(dim=None, sigma0=s0, sigma=s1, name='OrdWalk')\n",
    "PWalk_shock = NormalRW(dim=None, sigma0=s0, sigma=s_shock, name='ShockWalk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model coefficients\n",
    "gvar = GVAR(dim=dim[0]*dim[1], len=NUM_STEPS, name='coef_rw_inference')\n",
    "outputs = gvar.sample()\n",
    "# with tf.variable_scope('coefs_inference', dtype=floatX):\n",
    "#     gvar = DFlow([LinearChol(NUM_STEPS*dim[0]*dim[1], name='coef_rw_inference', use_bias=False)], init_sigma=0.02)\n",
    "#     outputs = tf.reshape(gvar.output, [1,NUM_STEPS, dim[0]*dim[1]])\n",
    "#     outputs = tf.cumsum(outputs, axis=1)\n",
    "#     mu = tf.get_variable('mu', [1,NUM_STEPS,dim[0]*dim[1]])\n",
    "#     outputs += mu\n",
    "\n",
    "tf.add_to_collection('logdensities', gvar.logdens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'coef_rw_inference_1/VAR/strided_slice_20:0' shape=(1, 20, 12) dtype=float64>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_ord = PWalk.logdens(outputs, reduce=False)\n",
    "prior_shock = PWalk_shock.logdens(outputs, reduce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'OrdWalk_2/concat:0' shape=(1, 20) dtype=float64>,\n",
       " <tf.Tensor 'ShockWalk_2/concat:0' shape=(1, 20) dtype=float64>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_ord, prior_shock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('Shock_Distr', reuse=tf.AUTO_REUSE):\n",
    "    shock_init_d = Normal([1,8])\n",
    "    shock_init = shock_init_d.sample()\n",
    "    \n",
    "    tf.add_to_collection('logdensities', shock_init_d.logdens(shock_init))\n",
    "    \n",
    "    shock_d = flows.dvae.RMultinomial([data.shape[1], 2], name='shock_distr')\n",
    "    shocks_soft_uncond, shocks_soft_cond, (shocks_hard, shocks_hard_logp, encoding_entropy) =\\\n",
    "    shock_d.encode(shock_init)\n",
    "    \n",
    "    shocks_hard_logp = tf.reduce_sum(shocks_hard_logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Shock_Distr/shock_distr/controls/Exp:0' shape=(20, 1) dtype=float64>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shock_d.temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Shock_Distr/shock_distr_1/encoder/latent_inf/Cast_1:0' shape=(1, 20, 2) dtype=float64>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shocks_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hard_shock_prior(num_shocks):\n",
    "    def c(n,k):\n",
    "        from scipy.special import binom\n",
    "        return tf.py_func(lambda x,y: int(binom(int(x),int(y))), [n, k], tf.int64)\n",
    "    \n",
    "    with tf.variable_scope('shocks_prior'):\n",
    "        spd = tf.contrib.distributions.Poisson(rate=NUM_STEPS/5.)\n",
    "        denum = tf.cast(c(NUM_STEPS, num_shocks), floatX)\n",
    "        return tf.cast(spd.log_prob(tf.cast(num_shocks, tf.float32)), floatX) - tf.log(denum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soft_shock_prior(num_shocks):\n",
    "#     return 0.\n",
    "    lower = tf.cast(tf.floor(num_shocks), floatX)\n",
    "    upper = lower + 1.\n",
    "    lh = create_hard_shock_prior(lower)\n",
    "    uh = create_hard_shock_prior(upper)\n",
    "    prop = num_shocks-lower\n",
    "    return lh*(1.-prop) + uh*prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_d_prior = LogNormal(dim=None, mu=math.log(0.5), sigma=0.5)\n",
    "\n",
    "with tf.variable_scope('obs_d_inference', dtype=floatX):\n",
    "    mu = tf.get_variable('mu', shape=[1], initializer=tf.constant_initializer(math.log(0.5)))\n",
    "    logsigma = tf.get_variable('logsigma', shape=[1], initializer=tf.constant_initializer(-5))\n",
    "    sigma = tf.exp(logsigma)\n",
    "    \n",
    "    obs_d_post = LogNormal(1, mu=mu, sigma=sigma)\n",
    "    obs_ds = obs_d_post.sample()\n",
    "    \n",
    "    obs_ds_logdens = obs_d_post.logdens(obs_ds)\n",
    "    tf.add_to_collection('logdensities', obs_ds_logdens)\n",
    "    tf.add_to_collection('priors', obs_d_prior.logdens(obs_ds))\n",
    "    \n",
    "    tf.summary.scalar('observ_sigma', obs_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_param_walk_prior(shocks):\n",
    "    with tf.name_scope('RW_prior'):\n",
    "        tmp = tf.cast(shocks[:,:,1], floatX)\n",
    "        print(tmp, prior_shock)\n",
    "        prior = tmp*prior_shock + (1-tmp)*prior_ord\n",
    "        print(prior)\n",
    "        prior = tf.reduce_sum(prior) \n",
    "        return prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(observable_mask):\n",
    "    out = tf.reshape(outputs, [NUM_STEPS, dim[0], dim[1]])\n",
    "    \n",
    "    def step(prev, x):\n",
    "        mask = x[0]\n",
    "        prev_pred = tf.where(mask, x[1], prev)[tf.newaxis]\n",
    "        params = x[2]\n",
    "        \n",
    "        d = params[:,:-1]\n",
    "        new_pred = tf.matmul(prev_pred, d)[0] + params[:,-1]\n",
    "        return new_pred\n",
    "    \n",
    "    ar = tf.scan(step, [observable_mask, data[0], out], initializer=tf.zeros([dim[0]], dtype=floatX))\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_time = tf.placeholder_with_default(NUM_STEPS, ())\n",
    "predict_mask = tf.range(0, data.shape[1], dtype=tf.int32) < stop_time\n",
    "#используем в предсказаниях ровно stop_time последних наблюдений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(predict_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'scan/TensorArrayStack/TensorArrayGatherV3:0' shape=(20, 3) dtype=float64>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_d = Normal(dim=None, sigma=obs_ds, mu=0)\n",
    "\n",
    "diffs = preds[:-1] - data[0,1:]\n",
    "\n",
    "logl = obs_d.logdens(diffs, reduce=False)\n",
    "logl *= tf.cast(predict_mask[:-1], floatX)[:,tf.newaxis]\n",
    "\n",
    "logl = tf.reduce_sum(logl)\n",
    "tf.add_to_collection('priors', logl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'logl:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar('logl', logl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kl(shocks, shocks_prior=0.):\n",
    "    logdens = tf.reduce_sum(tf.get_collection('logdensities'))\n",
    "    prior = tf.reduce_sum(tf.get_collection('priors'))\n",
    "    \n",
    "    param_walk_prior = create_param_walk_prior(shocks)\n",
    "    KLd = -prior + logdens - shocks_prior - param_walk_prior\n",
    "    KLd /= NUM_STEPS*dim[0]*dim[1]\n",
    "    return KLd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'walk_ord/LogNormal_2/Sum:0' shape=() dtype=float64>,\n",
       " <tf.Tensor 'walk_shock/LogNormal_2/Sum:0' shape=() dtype=float64>,\n",
       " <tf.Tensor 'coef_rw_inference_1/VAR/logdens/add:0' shape=() dtype=float64>,\n",
       " <tf.Tensor 'Shock_Distr/Normal_2/Sum:0' shape=() dtype=float64>,\n",
       " <tf.Tensor 'obs_d_inference/LogNormal_2/Sum:0' shape=() dtype=float64>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection('logdensities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'walk_ord/LogNormal_3/Sum:0' shape=() dtype=float64>,\n",
       " <tf.Tensor 'walk_shock/LogNormal_3/Sum:0' shape=() dtype=float64>,\n",
       " <tf.Tensor 'obs_d_inference/LogNormal_3/Sum:0' shape=() dtype=float64>,\n",
       " <tf.Tensor 'Sum:0' shape=() dtype=float64>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection('priors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Shock_Distr/shock_distr_1/encoder/latent_inf/Reshape_4:0' shape=(1, 20, 2) dtype=float64>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shocks_soft_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"RW_prior/strided_slice:0\", shape=(1, 20), dtype=float64) Tensor(\"ShockWalk_2/concat:0\", shape=(1, 20), dtype=float64)\n",
      "Tensor(\"RW_prior/add:0\", shape=(1, 20), dtype=float64)\n",
      "Tensor(\"RW_prior_1/strided_slice:0\", shape=(1, 20), dtype=float64) Tensor(\"ShockWalk_2/concat:0\", shape=(1, 20), dtype=float64)\n",
      "Tensor(\"RW_prior_1/add:0\", shape=(1, 20), dtype=float64)\n",
      "Tensor(\"RW_prior_2/strided_slice:0\", shape=(1, 20), dtype=float64) Tensor(\"ShockWalk_2/concat:0\", shape=(1, 20), dtype=float64)\n",
      "Tensor(\"RW_prior_2/add:0\", shape=(1, 20), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "num_shocks = tf.reduce_sum(shocks_soft_uncond[:,:,1:])\n",
    "ssp = create_soft_shock_prior(num_shocks) #- encoding_entropy\n",
    "soft_kl_uncond = create_kl(shocks_soft_uncond, shocks_prior=ssp)\n",
    "\n",
    "num_shocks = tf.reduce_sum(shocks_soft_cond[:,:,1:])\n",
    "ssp = create_soft_shock_prior(num_shocks) #- encoding_entropy\n",
    "soft_kl_cond = create_kl(shocks_soft_cond, shocks_prior=ssp)\n",
    "\n",
    "num_shocks = tf.reduce_sum(shocks_hard[:,:,1:])\n",
    "hard_shocks_prior = create_hard_shock_prior(num_shocks) - shocks_hard_logp\n",
    "hard_kl = create_kl(shocks_hard, shocks_prior=hard_shocks_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'num_shocks:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar('num_shocks', num_shocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Shock_Distr/Sum:0' shape=() dtype=float64>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shocks_hard_logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "relax_cond = shock_d.build_relax(tf.reshape(shocks_soft_cond, [1,-1]))\n",
    "relax_uncond = shock_d.build_relax(tf.reshape(shocks_soft_uncond, [1,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'truediv_1:0' shape=<unknown> dtype=float64>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_kl_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = shock_d.eta\n",
    "\n",
    "soft_control_cond = eta*soft_kl_cond + relax_cond\n",
    "soft_control_uncond = eta*soft_kl_uncond - eta*soft_kl_cond - relax_cond + relax_uncond\n",
    "\n",
    "stoped_grad = hard_kl - soft_control_cond# - nvil_baseline\n",
    "\n",
    "target = shocks_hard_logp*stoped_grad + soft_control_uncond\n",
    "target = tf.reduce_mean(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_8:0' shape=<unknown> dtype=float64>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_control_uncond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "shock_vars = shock_d.get_encoder_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "shock_vars_grad = tf.gradients(target, shock_vars, stop_gradients=stoped_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = shock_d.get_control_vars()\n",
    "cv_loss = shock_d.build_control_loss(shock_vars_grad)\n",
    "\n",
    "tf.summary.scalar('cv_loss', cv_loss)\n",
    "\n",
    "cv_gradients = tf.gradients(cv_loss, controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_vars = [x for x in tf.global_variables() if not (x in controls or x in shock_vars)]\n",
    "rest_gradients = tf.gradients(hard_kl, rest_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'walk_ord/s1_inference/mu:0' shape=(1,) dtype=float64_ref>,\n",
       " <tf.Variable 'walk_ord/s1_inference/logsigma:0' shape=(1,) dtype=float64_ref>,\n",
       " <tf.Variable 'walk_shock/incr_inference/mu:0' shape=(1,) dtype=float64_ref>,\n",
       " <tf.Variable 'walk_shock/incr_inference/logsigma:0' shape=(1,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_0/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_0/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_1/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_1/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_1/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_2/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_2/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_2/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_3/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_3/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_3/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_4/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_4/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_4/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_5/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_5/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_5/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_6/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_6/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_6/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_7/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_7/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_7/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_8/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_8/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_8/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_9/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_9/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_9/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_10/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_10/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_10/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_11/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_11/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_11/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_12/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_12/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_12/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_13/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_13/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_13/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_14/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_14/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_14/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_15/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_15/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_15/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_16/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_16/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_16/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_17/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_17/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_17/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_18/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_18/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_18/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_19/lowerd:0' shape=(78,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_19/ldiag:0' shape=(12,) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/lc_19/W:0' shape=(12, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'coef_rw_inference/mu:0' shape=(20, 12) dtype=float64_ref>,\n",
       " <tf.Variable 'obs_d_inference/mu:0' shape=(1,) dtype=float64_ref>,\n",
       " <tf.Variable 'obs_d_inference/logsigma:0' shape=(1,) dtype=float64_ref>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = shock_vars + rest_vars \n",
    "grads = shock_vars_grad + rest_gradients\n",
    "main_updates = [(g,x) for x,g in zip(all_vars, grads)]\n",
    "control_updates = [(g,x) for x,g in zip(controls, cv_gradients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'KLd:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar('KLd', hard_kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.Variable(0.0001)\n",
    "main_opt = tf.train.AdamOptimizer(lr).apply_gradients(main_updates)\n",
    "cont_opt = tf.train.AdamOptimizer(0.0003).apply_gradients(control_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor 'gradients_1/Shock_Distr/shock_distr/controls/Exp_grad/mul:0' shape=(20, 1) dtype=float64>,\n",
       "  <tf.Variable 'Shock_Distr/shock_distr/controls/pretemp:0' shape=(20, 1) dtype=float64_ref>),\n",
       " (<tf.Tensor 'gradients_1/Shock_Distr/shock_distr/controls/Exp_1_grad/mul:0' shape=() dtype=float64>,\n",
       "  <tf.Variable 'Shock_Distr/shock_distr/controls/preeta:0' shape=() dtype=float64_ref>),\n",
       " (<tf.Tensor 'gradients_1/AddN_30:0' shape=(40, 128) dtype=float64>,\n",
       "  <tf.Variable 'Shock_Distr/shock_distr/controls/RELAX/FCN/d0/W:0' shape=(40, 128) dtype=float64_ref>),\n",
       " (<tf.Tensor 'gradients_1/AddN_29:0' shape=(1, 128) dtype=float64>,\n",
       "  <tf.Variable 'Shock_Distr/shock_distr/controls/RELAX/FCN/d0/b:0' shape=(1, 128) dtype=float64_ref>),\n",
       " (<tf.Tensor 'gradients_1/AddN_24:0' shape=(128, 64) dtype=float64>,\n",
       "  <tf.Variable 'Shock_Distr/shock_distr/controls/RELAX/FCN/d1/W:0' shape=(128, 64) dtype=float64_ref>),\n",
       " (<tf.Tensor 'gradients_1/AddN_22:0' shape=(1, 64) dtype=float64>,\n",
       "  <tf.Variable 'Shock_Distr/shock_distr/controls/RELAX/FCN/d1/b:0' shape=(1, 64) dtype=float64_ref>),\n",
       " (<tf.Tensor 'gradients_1/AddN_20:0' shape=(64, 1) dtype=float64>,\n",
       "  <tf.Variable 'Shock_Distr/shock_distr/controls/RELAX/FCN/d2/W:0' shape=(64, 1) dtype=float64_ref>),\n",
       " (<tf.Tensor 'gradients_1/shock_distr/RELAX/FCN/strided_slice_grad/StridedSliceGrad:0' shape=(1, 1) dtype=float64>,\n",
       "  <tf.Variable 'Shock_Distr/shock_distr/controls/RELAX/FCN/d2/b:0' shape=(1, 1) dtype=float64_ref>)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = [main_opt, cont_opt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -R /tmp/tfdbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/tmp/tfdbg’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir /tmp/tfdbg\n",
    "writer = tf.summary.FileWriter('/tmp/tfdbg/proper_prior_var_rus_rate5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4826616862363935"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_kl.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'gradients_1/Shock_Distr/shock_distr/controls/Exp_grad/mul:0' shape=(20, 1) dtype=float64>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_gradients[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = []\n",
    "# for _ in range(1000):\n",
    "#     a.append(sess.run(cv_gradients[0]))\n",
    "# np.mean(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PWalk.inverse_sigma.eval()[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tf.reshape(outputs, [NUM_STEPS, dim[0], dim[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sum = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ppc(timestep):\n",
    "    n = 1000\n",
    "    all_preds = []\n",
    "    for _ in range(n):\n",
    "        tp = preds.eval({stop_time:timestep-1})\n",
    "        tp = tp[timestep-1]\n",
    "        all_preds.append(tp)\n",
    "    all_preds = np.array(all_preds).mean(axis=0)\n",
    "#     print(xs.shape)\n",
    "    return np.sqrt(np.mean((all_preds - xs[0,timestep])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shock_d.logits.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49864360372006283\n",
      "0.48699513269445377\n",
      "0.48691725565017546\n",
      "0.4798673087760238\n",
      "0.5116578162874476\n",
      "0.497947842735339\n",
      "0.5071439541876965\n",
      "0.49949462553892043\n",
      "0.4973035459889009\n",
      "0.5047347290325306\n",
      "0.5043938058508559\n",
      "0.5143573513899519\n",
      "0.48307976718990914\n",
      "0.5011605537787086\n",
      "0.500836212770811\n",
      "0.4961057770470087\n",
      "0.5054427637279403\n",
      "0.5119770859429006\n",
      "0.4994586034872988\n",
      "0.5356019286409761\n",
      "0.5172805770177277\n",
      "0.5037876270795139\n",
      "0.4904597398338131\n",
      "0.4879020493398544\n",
      "0.507563505677146\n",
      "0.5009605981639849\n",
      "0.4912599626210112\n",
      "0.4845515841433553\n",
      "0.4913508292589872\n",
      "0.49522819012963737\n",
      "0.5138675121830543\n",
      "0.4606450256519331\n",
      "0.4936171000752888\n",
      "0.4951396788331614\n",
      "0.49611079194537905\n",
      "0.5043524362764794\n",
      "0.5061495849987442\n",
      "0.5048439606622971\n",
      "0.4869371785725202\n",
      "0.47596875402914807\n",
      "0.5073555626804221\n",
      "0.507405041870599\n",
      "0.4758979778493952\n",
      "0.5154226508938635\n",
      "0.4766894256448045\n",
      "0.497176165176387\n",
      "0.48696472268906066\n",
      "0.48277567469778737\n",
      "0.48673879709734513\n",
      "0.507666259158345\n",
      "0.4877510086683389\n",
      "0.5030586508934931\n",
      "0.4884887316642306\n",
      "0.5034074874794655\n",
      "0.50691305400568\n",
      "0.5015333128575179\n",
      "0.5040787473306924\n",
      "0.5048945777852606\n",
      "0.47494831343115324\n",
      "0.4715874814070936\n",
      "0.4577569681569211\n",
      "0.4829961631281918\n",
      "0.5097478476773527\n",
      "0.4956511914549021\n",
      "0.49836325099017503\n",
      "0.5037514231078473\n",
      "0.46429429605166134\n",
      "0.4752700790280573\n",
      "0.48015230484357974\n",
      "0.5045219971496058\n",
      "0.5042631097829724\n",
      "0.46593132496707973\n",
      "0.4733223793868684\n",
      "0.5098280460730517\n",
      "0.49059065283756076\n",
      "0.49849339027902057\n",
      "0.5180963531999514\n",
      "0.5038506589326484\n",
      "0.5010443984248918\n",
      "0.5025988406924272\n",
      "0.4970693064907844\n",
      "0.501753738957211\n",
      "0.5046577334050568\n",
      "0.48501430410388857\n",
      "0.5055505061773995\n",
      "0.5017996650544347\n",
      "0.5000599237500118\n",
      "0.49110151695745924\n",
      "0.4990922427345571\n",
      "0.508912790880009\n",
      "0.5102123049721162\n",
      "0.5081430990465193\n",
      "0.5168981345300475\n",
      "0.4950840681459233\n",
      "0.5036217300480871\n",
      "0.5039713639638066\n",
      "0.4752656632371791\n",
      "0.5064489714668909\n",
      "0.490042309965042\n",
      "0.49657019276566244\n",
      "0.49510076613738646\n",
      "0.48090657662619235\n",
      "0.5065670896145192\n",
      "0.49379627254790226\n",
      "0.5076213428861834\n",
      "0.5108644023720397\n",
      "0.49724191518938454\n",
      "0.5120031593440395\n",
      "0.5119318726139179\n",
      "0.49397834360572546\n",
      "0.5021984530959682\n",
      "0.48308518099696157\n",
      "0.5005064589891387\n",
      "0.5038756424418634\n",
      "0.5141493867011664\n",
      "0.510092668923472\n",
      "0.5052253570499782\n",
      "0.47002146807215583\n",
      "0.5199075904741088\n",
      "0.5016313252621479\n",
      "0.5130999926579648\n",
      "0.4874770757431539\n",
      "0.49054951846302897\n",
      "0.4830195967875414\n",
      "0.4975563066671107\n",
      "0.5065212343884814\n",
      "0.4875138138580783\n",
      "0.5250303394531108\n",
      "0.5048761073353845\n",
      "0.49916009790513155\n",
      "0.5101824927611939\n",
      "0.4940372105744134\n",
      "0.4888796928547455\n",
      "0.4940394188089963\n",
      "0.48055031365267403\n",
      "0.4989897362519649\n",
      "0.49602549913254845\n",
      "0.489540735080278\n",
      "0.48463044846771147\n",
      "0.494126783323487\n",
      "0.4949494211001865\n",
      "0.5018473366344229\n",
      "0.48103597187747765\n",
      "0.4987855930936116\n",
      "0.49047431890988286\n",
      "0.5058253430969363\n",
      "0.4852832230342351\n",
      "0.5070170984791625\n",
      "0.5013250851173093\n",
      "0.5071561158586992\n",
      "0.47839547326640736\n",
      "0.48854172924606704\n",
      "0.5001995650676387\n",
      "0.5032819869551406\n",
      "0.4943815294723966\n",
      "0.4588137281402756\n",
      "0.44889485597826756\n",
      "0.5172235933949878\n",
      "0.5065758642741749\n",
      "0.5133064386773453\n",
      "0.49481744787425985\n",
      "0.47618054659967135\n",
      "0.49736186468640137\n",
      "0.4972204015388501\n",
      "0.49192570321478757\n",
      "0.4965140207503775\n",
      "0.48382946863994314\n",
      "0.49132887109081386\n",
      "0.4764363567718135\n",
      "0.4890062670888748\n",
      "0.5094037390359325\n",
      "0.4974703614550684\n",
      "0.5154574997253294\n",
      "0.4845788249272301\n",
      "0.5065945905221096\n",
      "0.5031004279116937\n",
      "0.49725611783744555\n",
      "0.4975877643563644\n",
      "0.4799655353963904\n",
      "0.46351053704778283\n",
      "0.489310180025249\n",
      "0.5000016790931966\n",
      "0.5031366803775399\n",
      "0.48704221136240117\n",
      "0.4945986561617905\n",
      "0.49574326336702607\n",
      "0.5103405177824473\n",
      "0.5048421326832556\n",
      "0.48000870256558364\n",
      "0.4956554641010963\n",
      "0.5019570910107911\n",
      "0.47827833702557093\n",
      "0.4937844465626393\n",
      "0.4929827152724485\n",
      "0.47867707909738966\n",
      "0.5053327398610835\n",
      "0.5118752853247028\n",
      "0.49984892387189933\n",
      "0.4832958861744951\n",
      "0.47084059876331613\n",
      "0.5178008692517186\n",
      "0.49731563401817475\n",
      "0.5017380350446776\n",
      "0.5088748543391953\n",
      "0.5118026238415522\n",
      "0.5139928923630497\n",
      "0.4934117558046651\n",
      "0.4515285108781974\n",
      "0.49475072459717473\n",
      "0.5105361213225343\n",
      "0.4980517777534639\n",
      "0.5001659008909873\n",
      "0.5157568690662248\n",
      "0.4938375265909618\n",
      "0.49631308590135553\n",
      "0.5081481311003808\n",
      "0.5017299135261939\n",
      "0.4926998516387388\n",
      "0.5052036905314945\n",
      "0.4784333848704013\n",
      "0.49710708482545435\n",
      "0.5078522227265821\n",
      "0.5027324553074382\n",
      "0.4856632011355039\n",
      "0.4935478929290369\n",
      "0.48577034318566065\n",
      "0.508150755216208\n",
      "0.4804634673294354\n",
      "0.47288896323610696\n",
      "0.5049445247790648\n",
      "0.4981395489749256\n",
      "0.46673037540964135\n",
      "0.5017112235370325\n",
      "0.5002104435474621\n",
      "0.49620172929672557\n",
      "0.5009069312238078\n",
      "0.5105116334900378\n",
      "0.5041900593471013\n",
      "0.496032077727673\n",
      "0.5054818527329014\n",
      "0.49828054878649275\n",
      "0.4870722353469889\n",
      "0.49343077191906226\n",
      "0.505247269065503\n",
      "0.4868673375640706\n",
      "0.5117808194391711\n",
      "0.47802013860508763\n",
      "0.5030817121016314\n",
      "0.5038113763023643\n",
      "0.4808616901868447\n",
      "0.4609472451048537\n",
      "0.5017372460850625\n",
      "0.4989583012895198\n",
      "0.5092877033998235\n",
      "0.5104405146764217\n",
      "0.490264982825785\n",
      "0.5048697123804277\n",
      "0.5579293918717629\n",
      "0.47993996599374594\n",
      "0.5190819035470788\n",
      "0.494619355622311\n",
      "0.4921745396573821\n",
      "0.4720532693544747\n",
      "0.4987187370501052\n",
      "0.5105180897910856\n",
      "0.4909892130670073\n",
      "0.49856628711753664\n",
      "0.5099198940621716\n",
      "0.5032168104955396\n",
      "0.49802184398307264\n",
      "0.4852885673837958\n",
      "0.49443172726533596\n",
      "0.5089769941178185\n",
      "0.5165636575205202\n",
      "0.5068548621382595\n",
      "0.5088018731394428\n",
      "0.4908690142292843\n",
      "0.48459211545522296\n",
      "0.5165694692235689\n",
      "0.5014851191049511\n",
      "0.5003875507952334\n",
      "0.4949788157300252\n",
      "0.4691316265990016\n",
      "0.4856543742740245\n",
      "0.5119115165770024\n",
      "0.49396612947872426\n",
      "0.49431457073887963\n",
      "0.4947240932660179\n",
      "0.5055003864893275\n",
      "0.5074283772894326\n",
      "0.5020359637473641\n",
      "0.5070131493796569\n",
      "0.47312629592263655\n",
      "0.48594967631581343\n",
      "0.502625083266592\n",
      "0.4992377793464887\n",
      "0.5016438018699538\n",
      "0.4911164379957041\n",
      "0.5260254411274748\n",
      "0.49559189690230526\n",
      "0.49129770386886923\n",
      "0.45668826320424927\n",
      "0.4984034707853529\n",
      "0.5054084057724789\n",
      "0.4895613828437471\n",
      "0.5092760423230938\n",
      "0.49754661407306455\n",
      "0.49007841793545526\n",
      "0.5039042647792649\n",
      "0.5037724869687603\n",
      "0.5073451470821316\n",
      "0.5089753633360521\n",
      "0.4920820838707608\n",
      "0.49555902699488996\n",
      "0.5050348154735851\n",
      "0.49606802880755485\n",
      "0.5048170801868598\n",
      "0.50536255013109\n",
      "0.476618230426715\n",
      "0.4983208502801934\n",
      "0.49552903703347273\n",
      "0.49125516471557945\n",
      "0.48665368333404097\n",
      "0.514722513852955\n",
      "0.4856465040908018\n",
      "0.47732441146383453\n",
      "0.5007662057543605\n",
      "0.5115719079551851\n",
      "0.4903350095528566\n",
      "0.49923764447403157\n",
      "0.49588765505200694\n",
      "0.4989022149044544\n",
      "0.48286346848516054\n",
      "0.4890663985119948\n",
      "0.48679933736063724\n",
      "0.5121087202096867\n",
      "0.48606163242744505\n",
      "0.48220727669077873\n",
      "0.5174298208437558\n",
      "0.482353300653273\n",
      "0.49336403741793927\n",
      "0.49989419929533224\n",
      "0.47467538528855824\n",
      "0.495293473899625\n",
      "0.5061608157455841\n",
      "0.5115598062237244\n",
      "0.48456577740643214\n",
      "0.49025140532819594\n",
      "0.5040781735008408\n",
      "0.48585759225766956\n",
      "0.48597350808235096\n",
      "0.5104671217425543\n",
      "0.4844776655033963\n",
      "0.5194225764842593\n",
      "0.5055997836947443\n",
      "0.5043959874894071\n",
      "0.4577473725811217\n",
      "0.505034243572423\n",
      "0.500915432161582\n",
      "0.5140336486103465\n",
      "0.4928357708756162\n",
      "0.489403890207573\n",
      "0.4921562659374236\n",
      "0.49138243084095046\n",
      "0.48965556201336163\n",
      "0.5157693704148746\n",
      "0.49895810739676894\n",
      "0.5011834515023258\n",
      "0.5043050407110854\n",
      "0.5059974489492196\n",
      "0.4980881998736637\n",
      "0.49606494338588264\n",
      "0.5076971486490803\n",
      "0.4966214804600168\n",
      "0.48370516654717527\n",
      "0.4816886213747523\n",
      "0.4925441821421302\n",
      "0.5016205861504247\n",
      "0.4777561562781017\n",
      "0.5160140207678272\n",
      "0.5062523731678008\n",
      "0.4941749631289634\n",
      "0.503842157146993\n",
      "0.5033489627322444\n",
      "0.5036869843420824\n",
      "0.4989948490713251\n",
      "0.4970836443140082\n",
      "0.49856915323590556\n",
      "0.49279801545856167\n",
      "0.49450140454987235\n",
      "0.4987930809480183\n",
      "0.4833461035578895\n",
      "0.504569275387073\n",
      "0.515245847388817\n",
      "0.5306815684647174\n",
      "0.49866198947752477\n",
      "0.5107727249146014\n",
      "0.5116395990727959\n",
      "0.49237679581371957\n",
      "0.4869370160205236\n",
      "0.49285946003015463\n",
      "0.49773014135819055\n",
      "0.49103434851029654\n",
      "0.5030198780260444\n",
      "0.49453612898597943\n",
      "0.495454310417396\n",
      "0.5073676417905456\n",
      "0.5048880478543756\n",
      "0.5047570799531181\n",
      "0.5114415812531303\n",
      "0.5042563209647395\n",
      "0.49464999281469396\n",
      "0.4928064859561114\n",
      "0.5060826738272008\n",
      "0.4919776075686469\n",
      "0.5078478363796454\n",
      "0.4941932059233558\n",
      "0.5162837240811148\n",
      "0.49390957038460265\n",
      "0.48611486763249917\n",
      "0.48254972091632925\n",
      "0.5085201963265285\n",
      "0.498946181049939\n",
      "0.503510485591373\n",
      "0.5093279515680185\n",
      "0.5157996639639746\n",
      "0.5000913424623366\n",
      "0.49091765616368854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48195605510128703\n",
      "0.4765374374184328\n",
      "0.4928669745582724\n",
      "0.47611347713980834\n",
      "0.5076881850920709\n",
      "0.48821632512626156\n",
      "0.5030800000451795\n",
      "0.5042729857653555\n",
      "0.5044594681934138\n",
      "0.4933177998275518\n",
      "0.49397911208102985\n",
      "0.5043514156968688\n",
      "0.49031984387632643\n",
      "0.5272428476602881\n",
      "0.4956777070745877\n",
      "0.5065303873124278\n",
      "0.4975993038451532\n",
      "0.5081268393516986\n",
      "0.4868501737634645\n",
      "0.512632647054711\n",
      "0.5024243181401176\n",
      "0.5008885776959161\n",
      "0.4856099471175412\n",
      "0.5047524377997228\n",
      "0.49253083796111524\n",
      "0.5111094478382625\n",
      "0.5168544817192811\n",
      "0.4994592493089913\n",
      "0.5081318404237957\n",
      "0.5046651747875088\n",
      "0.5010008913958849\n",
      "0.49592168122566327\n",
      "0.47607496024453394\n",
      "0.5008365088525882\n",
      "0.5078144062147439\n",
      "0.5238853911257465\n",
      "0.5193544422665506\n",
      "0.452504134813248\n",
      "0.5199162337017124\n",
      "0.49730743749544953\n",
      "0.5054765624382728\n",
      "0.5006887596246604\n",
      "0.4775498170051016\n",
      "0.5042070514949785\n",
      "0.4968415977450858\n",
      "0.5097261793011566\n",
      "0.4993488417579873\n",
      "0.46930468179632806\n",
      "0.4855345944196609\n",
      "0.5052846319488343\n",
      "0.5049438337412437\n",
      "0.4676723341318128\n",
      "0.51097557444523\n",
      "0.5026701392602959\n",
      "0.48649137490502004\n",
      "0.4845404037745773\n",
      "0.5072788789771873\n",
      "0.4681888295888001\n",
      "0.4953237020282332\n",
      "0.4992555391997655\n",
      "0.4943900787615964\n",
      "0.5049710656067135\n",
      "0.4901714589958251\n",
      "0.4857310999992535\n",
      "0.48727838715982846\n",
      "0.47025713949772124\n",
      "0.4942224669129336\n",
      "0.5108015566376546\n",
      "0.4966232147051\n",
      "0.5131814635374935\n",
      "0.5056863300308614\n",
      "0.4989688291230408\n",
      "0.4597443294310144\n",
      "0.5011045002937621\n",
      "0.4929200309856891\n",
      "0.4971098546091689\n",
      "0.4900446645768151\n",
      "0.5145877537905662\n",
      "0.5046668816264396\n",
      "0.5066713676941969\n",
      "0.5051580402523219\n",
      "0.4923313293971608\n",
      "0.4913072987355432\n",
      "0.4891173772243713\n",
      "0.4815048569261409\n",
      "0.4863242821015902\n",
      "0.5086838225297873\n",
      "0.48823151501023004\n",
      "0.49289562728211844\n",
      "0.48789092340820567\n",
      "0.4960418083647378\n",
      "0.5123953852837403\n",
      "0.49015601297623446\n",
      "0.5070423436885366\n",
      "0.49886166000964827\n",
      "0.5121042514713398\n",
      "0.5059505981369274\n",
      "0.4841076186892953\n",
      "0.4825379935888743\n",
      "0.5094107963749245\n",
      "0.5002623900613495\n",
      "0.5072696885571835\n",
      "0.5001232921009492\n",
      "0.49615640100910263\n",
      "0.5075870864135662\n",
      "0.4684212909827219\n",
      "0.4898754192208154\n",
      "0.49939868333499243\n",
      "0.5102114451035864\n",
      "0.4886489226539185\n",
      "0.5042133122043936\n",
      "0.48685093185365486\n",
      "0.49628310792976554\n",
      "0.5010669537699234\n",
      "0.4940711707410107\n",
      "0.4969878476384016\n",
      "0.4885171572024021\n",
      "0.5026040204141926\n",
      "0.5044901200135902\n",
      "0.5019694179208756\n",
      "0.4745187404674856\n",
      "0.5053652271820449\n",
      "0.48523803106408964\n",
      "0.48534779666133165\n",
      "0.48031603461124583\n",
      "0.5017642403804141\n",
      "0.5212318153277091\n",
      "0.47455910861195133\n",
      "0.49802974801513833\n",
      "0.49685835114491844\n",
      "0.4907659952683356\n",
      "0.5113006737825889\n",
      "0.5012064688037057\n",
      "0.49306013596566534\n",
      "0.5083364688347544\n",
      "0.5052262529528818\n",
      "0.511565120088412\n",
      "0.48715493605018545\n",
      "0.5015730334342424\n",
      "0.525737400219356\n",
      "0.5132791137969626\n",
      "0.5054938592041267\n",
      "0.49980553348911605\n",
      "0.4808185502728598\n",
      "0.46729478419370596\n",
      "0.4776422757215812\n",
      "0.48217871663956446\n",
      "0.48655120494097515\n",
      "0.5124528368658593\n",
      "0.48766244388612706\n",
      "0.4797777292198859\n",
      "0.5134356038062828\n",
      "0.5058446056552808\n",
      "0.5145461335739309\n",
      "0.49781343311413145\n",
      "0.49742461930229875\n",
      "0.5085887832138155\n",
      "0.493620114079742\n",
      "0.5049332742628039\n",
      "0.5062220386675951\n",
      "0.5073014837975033\n",
      "0.5015593558222576\n",
      "0.5045403670448709\n",
      "0.5014206582070562\n",
      "0.488982335493556\n",
      "0.4948928733671778\n",
      "0.5126401976131117\n",
      "0.5006016896799342\n",
      "0.5059293028033401\n",
      "0.5000517065809797\n",
      "0.4915535023264411\n",
      "0.4914949115819274\n",
      "0.4975533838142648\n",
      "0.4985827439865266\n",
      "0.4837033625724224\n",
      "0.49382566806143324\n",
      "0.48705342064801255\n",
      "0.4863219932244391\n",
      "0.5011190930549659\n",
      "0.49956321738543585\n",
      "0.48344405743531194\n",
      "0.488036292883046\n",
      "0.4898239755338395\n",
      "0.49075481951644234\n",
      "0.5098963637070928\n",
      "0.506843766030801\n",
      "0.5098843901555751\n",
      "0.5057872546890027\n",
      "0.5145782727930521\n",
      "0.49776006591466787\n",
      "0.49175847331930383\n",
      "0.5075123154112944\n",
      "0.497074866584543\n",
      "0.4915747993322777\n",
      "0.5043187109674986\n",
      "0.4962151242582256\n",
      "0.4830968723587456\n",
      "0.5079317493364257\n",
      "0.48469079884976957\n",
      "0.5081564445860669\n",
      "0.4735824052249981\n",
      "0.504736514717518\n",
      "0.5138954486879624\n",
      "0.495254013778306\n",
      "0.4691618801761607\n",
      "0.5087102953586569\n",
      "0.49679554235091883\n",
      "0.4796211045517552\n",
      "0.5137309577580571\n",
      "0.511937368583752\n",
      "0.4870842091565194\n",
      "0.4952279291318992\n",
      "0.482607877822961\n",
      "0.4821778292948257\n",
      "0.504455234989535\n",
      "0.5156613365611035\n",
      "0.49165306293122485\n",
      "0.5112475142125816\n",
      "0.5100479536002855\n",
      "0.4874454412598903\n",
      "0.4971053863298901\n",
      "0.49451623362536407\n",
      "0.5000800080195825\n",
      "0.499399444118832\n",
      "0.5029856671416465\n",
      "0.4887511024374064\n",
      "0.5159854135885585\n",
      "0.5079305229111128\n",
      "0.49834155028360383\n",
      "0.4924432664907653\n",
      "0.537908242278731\n",
      "0.4829055909793335\n",
      "0.5092261761777176\n",
      "0.5037050382568832\n",
      "0.5037726200595557\n",
      "0.5030094840658352\n",
      "0.5149630723807306\n",
      "0.447670901633686\n",
      "0.5030296495971314\n",
      "0.49197234482511004\n",
      "0.47759674306942607\n",
      "0.4843622052407691\n",
      "0.4900694062529856\n",
      "0.4962938576364434\n",
      "0.4859108722284361\n",
      "0.4906589024534135\n",
      "0.5001498857124076\n",
      "0.5116138493244496\n",
      "0.5001061091237188\n",
      "0.4950539652776662\n",
      "0.5020114980372488\n",
      "0.49919046341053885\n",
      "0.5084827386192934\n",
      "0.5098834002316937\n",
      "0.4996651854117739\n",
      "0.49588977667857154\n",
      "0.48352016627322786\n",
      "0.48394748513164104\n",
      "0.5020271802848775\n",
      "0.4836613365546183\n",
      "0.5149062878097143\n",
      "0.49120533907041636\n",
      "0.4864266848894507\n",
      "0.5024958972689186\n",
      "0.49397270152391903\n",
      "0.508286543667055\n",
      "0.5129318241292599\n",
      "0.48677605019222436\n",
      "0.4859839327921118\n",
      "0.5067883115999966\n",
      "0.4791595239264147\n",
      "0.49413565016373107\n",
      "0.5002709902036869\n",
      "0.5035249980273906\n",
      "0.5063910094805143\n",
      "0.49023502370140665\n",
      "0.5010298306551223\n",
      "0.5142696731685897\n",
      "0.489536311607417\n",
      "0.5075035616772029\n",
      "0.4802875413106385\n",
      "0.48977605516782696\n",
      "0.5252912308241787\n",
      "0.5167367569058227\n",
      "0.5217241558703708\n",
      "0.5031228380973353\n",
      "0.5009219633646786\n",
      "0.5023848535018597\n",
      "0.49774846891478597\n",
      "0.48171500216452234\n",
      "0.49045150494023676\n",
      "0.4933363369122591\n",
      "0.4985487416771451\n",
      "0.49205819478571583\n",
      "0.5028956664446821\n",
      "0.506092531039437\n",
      "0.515977405242266\n",
      "0.5165937608967108\n",
      "0.5167161692075986\n",
      "0.5088184539373785\n",
      "0.4784736482251849\n",
      "0.4808327779934932\n",
      "0.4935056877558916\n",
      "0.477672199363109\n",
      "0.4948506875011096\n",
      "0.49930623400806645\n",
      "0.512485810915377\n",
      "0.4923006097618336\n",
      "0.4870210110182432\n",
      "0.5022883332072077\n",
      "0.5061135368985049\n",
      "0.4833237449429115\n",
      "0.5019386484148505\n",
      "0.4987233778860561\n",
      "0.48402780350903024\n",
      "0.5127519140617925\n",
      "0.48350825066321995\n",
      "0.49650612929039684\n",
      "0.48539547587201215\n",
      "0.49653862082445077\n",
      "0.49914928920881724\n",
      "0.5041356478799796\n",
      "0.5154139093820369\n",
      "0.5084842582372479\n",
      "0.5041659683445441\n",
      "0.5098824258513093\n",
      "0.49384272234850995\n",
      "0.5050022423093494\n",
      "0.498860532135465\n",
      "0.4978592462828232\n",
      "0.5142413802632418\n",
      "0.4877804079976066\n",
      "0.5060788452868255\n",
      "0.4977501555786915\n",
      "0.5103012214430781\n",
      "0.5065695491957759\n",
      "0.4973398152096228\n",
      "0.4879599513771164\n",
      "0.4952002366511214\n",
      "0.5141664302367331\n",
      "0.47094808815625555\n",
      "0.46721875252846795\n",
      "0.512073676146083\n",
      "0.5151097255600178\n",
      "0.4592890291761783\n",
      "0.49316497272204884\n",
      "0.5039828335928099\n",
      "0.529703955111876\n",
      "0.5044039873248504\n",
      "0.5034991144356246\n",
      "0.5137768656696555\n",
      "0.4856967696116989\n",
      "0.4931659938949411\n",
      "0.5009800973896378\n",
      "0.5039773747490567\n",
      "0.5040401784521005\n",
      "0.47760813595427437\n",
      "0.5012749375699445\n",
      "0.4913754231781482\n",
      "0.5027791484285971\n",
      "0.4977785183387001\n",
      "0.5055154106190446\n",
      "0.49572568450523086\n",
      "0.49136269462816007\n",
      "0.4810839825929598\n",
      "0.49128902662238333\n",
      "0.5056204360243439\n",
      "0.48918539016931767\n",
      "0.4754321313186736\n",
      "0.5120184550791459\n",
      "0.49884452279601965\n",
      "0.4974273128454513\n",
      "0.485389709481412\n",
      "0.4874199492563439\n",
      "0.4883574824151424\n",
      "0.4962968984222528\n",
      "0.4871875744804479\n",
      "0.5042112356293077\n",
      "0.5106045637262558\n",
      "0.5177131491840977\n",
      "0.5065954501923545\n",
      "0.4930092235602193\n",
      "0.5107356889732173\n",
      "0.47505608903920304\n",
      "0.4846399770893053\n",
      "0.48799520907385935\n",
      "0.4659137022113557\n",
      "0.49988267808404624\n",
      "0.48394067441204525\n",
      "0.49808389571531086\n",
      "0.48060652498343565\n",
      "0.49535586376692087\n",
      "0.48476315641661855\n",
      "0.5017667968303414\n",
      "0.4855461818621199\n",
      "0.483344766833126\n",
      "0.4881545718704094\n",
      "0.49615435840534894\n",
      "0.5023799364373086\n",
      "0.5134582071893495\n",
      "0.5008912224017934\n",
      "0.49487227708187026\n",
      "0.4906502230712159\n",
      "0.4896086538849592\n",
      "0.4950120199716681\n",
      "0.4887603725040672\n",
      "0.49884426252748093\n",
      "0.4925243326784553\n",
      "0.4828260483582113\n",
      "0.5052506650886338\n",
      "0.48554547084579575\n",
      "0.47270418959494076\n",
      "0.49949923053674683\n",
      "0.4782611990056206\n",
      "0.4842521499729289\n",
      "0.490499985454548\n",
      "0.4945537314931182\n",
      "0.517818286327176\n",
      "0.5077495924345804\n",
      "0.48949452559859047\n",
      "0.4972586944449181\n",
      "0.5057845591119654\n",
      "0.5015943722969128\n",
      "0.513455984435278\n",
      "0.5120582123934843\n",
      "0.49235055777689873\n",
      "0.5002193192585215\n",
      "0.501346047628617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.490349815284204\n",
      "0.5082958858897709\n",
      "0.4778147427589156\n",
      "0.4940621710337017\n",
      "0.49473727281954183\n",
      "0.4843654007233738\n",
      "0.49894458886619425\n",
      "0.4899369566258673\n",
      "0.4657525761205953\n",
      "0.5109391773840202\n",
      "0.49961923653848167\n",
      "0.5177321842159702\n",
      "0.4964413579062954\n",
      "0.5161919840164461\n",
      "0.5181155204083507\n",
      "0.4738782983107574\n",
      "0.49929092132433606\n",
      "0.5048274394263944\n",
      "0.49876623714154417\n",
      "0.5046019011615852\n",
      "0.480997795775207\n",
      "0.4985079675118134\n",
      "0.5216487183613014\n",
      "0.49721635577608225\n",
      "0.48250953327451546\n",
      "0.5484945238200687\n",
      "0.48517389208202294\n",
      "0.48731196890261663\n",
      "0.4960318840476958\n",
      "0.4832595928064388\n",
      "0.48715927530179215\n",
      "0.49691670085215495\n",
      "0.5038180134686466\n",
      "0.5119214229255173\n",
      "0.4932876448742116\n",
      "0.4869449678713451\n",
      "0.49562910452465353\n",
      "0.5105401962731582\n",
      "0.5020150325266054\n",
      "0.5033265308077605\n",
      "0.5002042871369918\n",
      "0.481744642640165\n",
      "0.48485924600746366\n",
      "0.47894744369878545\n",
      "0.5004878232345668\n",
      "0.5017827953456028\n",
      "0.5026260692760459\n",
      "0.5263615073773363\n",
      "0.494275073427184\n",
      "0.49348601229286354\n",
      "0.4882256600048668\n",
      "0.5034231661130225\n",
      "0.4996909517507054\n",
      "0.49948578826629914\n",
      "0.5227810663622013\n",
      "0.5215396920747895\n",
      "0.48627009878854277\n",
      "0.5130017290713913\n",
      "0.48035907054738564\n",
      "0.5122485672482526\n",
      "0.5174243609951361\n",
      "0.48407890851531454\n",
      "0.4746589080708714\n",
      "0.5081444487080992\n",
      "0.51271079835573\n",
      "0.516173265094198\n",
      "0.4886188415547987\n",
      "0.49673126379290977\n",
      "0.5008893282357576\n",
      "0.5062900970264725\n",
      "0.4950613013447215\n",
      "0.4950314241169631\n",
      "0.4858637962011514\n",
      "0.508871589996658\n",
      "0.49743248581105654\n",
      "0.49166149093416084\n",
      "0.49741633870165813\n",
      "0.5053976482563466\n",
      "0.47012362872196767\n",
      "0.4765781287923007\n",
      "0.5009820156975984\n",
      "0.48262511708318384\n",
      "0.4842198554214197\n",
      "0.4971767598521204\n",
      "0.4821906936803236\n",
      "0.497634028829062\n",
      "0.48295112358388603\n",
      "0.5072948252441918\n",
      "0.5023157292077769\n",
      "0.4869404477981876\n",
      "0.49469742326390737\n",
      "0.5050928892641257\n",
      "0.5076498057660364\n",
      "0.48925427821945344\n",
      "0.4811192801525204\n",
      "0.5093267044837527\n",
      "0.5022390490191727\n",
      "0.5120876992156539\n",
      "0.49009066938456414\n",
      "0.49808055700194986\n",
      "0.5049787743451025\n",
      "0.48984573684080457\n",
      "0.4870274794919853\n",
      "0.4807596010525887\n",
      "0.5125366629913078\n",
      "0.5001413075421378\n",
      "0.48626567288122047\n",
      "0.486327721991123\n",
      "0.5040675216975539\n",
      "0.5051817394175591\n",
      "0.5094758696425008\n",
      "0.5006808350411631\n",
      "0.5065027633623752\n",
      "0.46267918770517347\n",
      "0.4827695427393621\n",
      "0.501189570357194\n",
      "0.4920175514221602\n",
      "0.49477243980369395\n",
      "0.48637253944449793\n",
      "0.48710534915490483\n",
      "0.4687773001702846\n",
      "0.5056876934465642\n",
      "0.5145388075875303\n",
      "0.5236839968801751\n",
      "0.5185327236359333\n",
      "0.4758742209882432\n",
      "0.5016160098271143\n",
      "0.4964689865277672\n",
      "0.5042932404862707\n",
      "0.5044981017894524\n",
      "0.512031675670211\n",
      "0.5036096496789138\n",
      "0.488961307963946\n",
      "0.5157365664533275\n",
      "0.48980601900469267\n",
      "0.48555556909672504\n",
      "0.49214301091189394\n",
      "0.5088835124014343\n",
      "0.5092030518364955\n",
      "0.48170890168108094\n",
      "0.5088934799497647\n",
      "0.47419372464554216\n",
      "0.4752376649183122\n",
      "0.4985950945795691\n",
      "0.49537467684951697\n",
      "0.4877607600646447\n",
      "0.4871920066163296\n",
      "0.476102321571701\n",
      "0.5022147907527156\n",
      "0.5001632553076834\n",
      "0.49697464488410076\n",
      "0.5075384504439039\n",
      "0.5018490111965525\n",
      "0.504433788916001\n",
      "0.4803444113032041\n",
      "0.5133839003993368\n",
      "0.48964671063086246\n",
      "0.4692680368841375\n",
      "0.4937652794252202\n",
      "0.512292296980416\n",
      "0.4974989875391387\n",
      "0.5033372833212402\n",
      "0.49778849749582527\n",
      "0.5067794951042343\n",
      "0.4946630210360359\n",
      "0.4788487933561193\n",
      "0.5055594455179384\n",
      "0.4898701563269962\n",
      "0.4821332913950336\n",
      "0.4969291278376138\n",
      "0.49868605390549636\n",
      "0.48922955470387514\n",
      "0.48309115058453195\n",
      "0.5064144396487933\n",
      "0.5016808241988019\n",
      "0.5159883477236186\n",
      "0.5024457332373802\n",
      "0.48779446626768297\n",
      "0.4988089661334939\n",
      "0.4994479487442009\n",
      "0.4801283514579235\n",
      "0.47885795572754214\n",
      "0.5066261592346478\n",
      "0.5022128725440169\n",
      "0.493065120390267\n",
      "0.5135092806290459\n",
      "0.5266018762634634\n",
      "0.4885259100079097\n",
      "0.4899688294980834\n",
      "0.49894845609886646\n",
      "0.48325525234878436\n",
      "0.5072868818811905\n",
      "0.50621403411763\n",
      "0.48513081859543\n",
      "0.5082213223171228\n",
      "0.5060268422866213\n",
      "0.4963109288096395\n",
      "0.5103289288639705\n",
      "0.5118303070534381\n",
      "0.49542587178967495\n",
      "0.48809033762739984\n",
      "0.4965780049955043\n",
      "0.4851440892975672\n",
      "0.5081936981916335\n",
      "0.5201036803600928\n",
      "0.4886566101325528\n",
      "0.5086458355520094\n",
      "0.4769397761751968\n",
      "0.4808543061123949\n",
      "0.5049273025253586\n",
      "0.501580132710725\n",
      "0.5077249980618002\n",
      "0.490346706274111\n",
      "0.47868832578548226\n",
      "0.5105719374771664\n",
      "0.49526239361107494\n",
      "0.49778738199502137\n",
      "0.4963758712298187\n",
      "0.4884866532871425\n",
      "0.4704145990518754\n",
      "0.5030465095288957\n",
      "0.4927636290329119\n",
      "0.48773871379911404\n",
      "0.4932466877058701\n",
      "0.4881706704740166\n",
      "0.5031207839158041\n",
      "0.5133978909849408\n",
      "0.5097769339389979\n",
      "0.4909955107978992\n",
      "0.49262695097066334\n",
      "0.5038390088012439\n",
      "0.49430216600925597\n",
      "0.46560032462379913\n",
      "0.5131735940872164\n",
      "0.49596640943652803\n",
      "0.4851541108662995\n",
      "0.4855410627524364\n",
      "0.5240382503026405\n",
      "0.5129137952795996\n",
      "0.4956336600016182\n",
      "0.49660640879041223\n",
      "0.5137326452898814\n",
      "0.539347523995432\n",
      "0.47675450315307727\n",
      "0.5062464287031709\n",
      "0.5089580895546589\n",
      "0.4936865707029507\n",
      "0.45216909990166604\n",
      "0.5236217747214833\n",
      "0.5024150711974154\n",
      "0.5135558336729343\n",
      "0.5165855023614844\n",
      "0.4854832686539661\n",
      "0.5077016478709647\n",
      "0.48564772552293434\n",
      "0.5090986710206432\n",
      "0.5028064246377691\n",
      "0.496823842655634\n",
      "0.4962324674602314\n",
      "0.4757874444340426\n",
      "0.5037095717415013\n",
      "0.4878114602054739\n",
      "0.48060456076955776\n",
      "0.5156862853653631\n",
      "0.5194891977669219\n",
      "0.4834598708598899\n",
      "0.5055057895090823\n",
      "0.48623177605954854\n",
      "0.500576573696442\n",
      "0.4995012001862804\n",
      "0.4869953773085435\n",
      "0.4770809797633542\n",
      "0.49259760133137387\n",
      "0.4930025066595628\n",
      "0.504385849256972\n",
      "0.516504037259233\n",
      "0.4948248738423255\n",
      "0.4868707064625061\n",
      "0.506658785460773\n",
      "0.5156378608316243\n",
      "0.5299277740071064\n",
      "0.5154599223399475\n",
      "0.4989630365555958\n",
      "0.49479870539436915\n",
      "0.48203178065405416\n",
      "0.49066442771744384\n",
      "0.4692731712205211\n",
      "0.5069024722927762\n",
      "0.49157478331634674\n",
      "0.4704159708205227\n",
      "0.48805952288798005\n",
      "0.4985970198276154\n",
      "0.48685413701292124\n",
      "0.49652599041048073\n",
      "0.5064568795471066\n",
      "0.5052819729227778\n",
      "0.5046847039359909\n",
      "0.49020876331161245\n",
      "0.49251520644855307\n",
      "0.48710899783834755\n",
      "0.5012137112237888\n",
      "0.5137543379943484\n",
      "0.4772212743171456\n",
      "0.4885001057974819\n",
      "0.48299582352949266\n",
      "0.5005034277229996\n",
      "0.503818751917675\n",
      "0.5092383430532538\n",
      "0.4987090412434732\n",
      "0.5043846509322485\n",
      "0.5171695836303485\n",
      "0.5057070464329698\n",
      "0.4994230470676849\n",
      "0.5148959244216589\n",
      "0.4983599528916855\n",
      "0.5084894318251476\n",
      "0.471708626708147\n",
      "0.4903859479410739\n",
      "0.4930682183943186\n",
      "0.49717544900723637\n",
      "0.49722808683990916\n",
      "0.4807755936472257\n",
      "0.46043034833822627\n",
      "0.5035229092074246\n",
      "0.49696841797868696\n",
      "0.4963200039818512\n",
      "0.5053841410046384\n",
      "0.49130396268907717\n",
      "0.48296697335976785\n",
      "0.504635942932935\n",
      "0.5080755777432306\n",
      "0.5015419607644993\n",
      "0.48820226588023774\n",
      "0.4889571553262428\n",
      "0.49367530330287435\n",
      "0.4813359725858703\n",
      "0.500520947861318\n",
      "0.5014555981345278\n",
      "0.5075589215119923\n",
      "0.49400457716829915\n",
      "0.5067931888938672\n",
      "0.49033400146339545\n",
      "0.5033107813661332\n",
      "0.5129418601305259\n",
      "0.4990257330472114\n",
      "0.5071563313615869\n",
      "0.5037633457766082\n",
      "0.5116531592435768\n",
      "0.5054315878889788\n",
      "0.49197428474042654\n",
      "0.5053787021821686\n",
      "0.4950860225672488\n",
      "0.5097679264009448\n",
      "0.49634657816894434\n",
      "0.4913711877111363\n",
      "0.45179082342441795\n",
      "0.4899910162730414\n",
      "0.5274738967147047\n",
      "0.49754959753111005\n",
      "0.48926409715375196\n",
      "0.505243087558426\n",
      "0.5160566177474919\n",
      "0.5078920601082608\n",
      "0.5113956718472022\n",
      "0.49143966737106104\n",
      "0.5158487655792536\n",
      "0.5178731617386803\n",
      "0.4998138836422636\n",
      "0.5144398290388122\n",
      "0.5104140420355425\n",
      "0.49593623497138967\n",
      "0.4967444789701292\n",
      "0.4863996065993613\n",
      "0.5187107504930988\n",
      "0.46081234323738207\n",
      "0.501004224600878\n",
      "0.4950614015935642\n",
      "0.5151876989894253\n",
      "0.4992879602976899\n",
      "0.4813312808935947\n",
      "0.49702430747933213\n",
      "0.49797425601146655\n",
      "0.5122082228575053\n",
      "0.49790330306548775\n",
      "0.5119239248584573\n",
      "0.5071198692728075\n",
      "0.4914173381989305\n",
      "0.5039352589509747\n",
      "0.5105770094955143\n",
      "0.4980633872110085\n",
      "0.5033098123229597\n",
      "0.520614818592253\n",
      "0.49507058870670756\n",
      "0.5104245450800202\n",
      "0.5276251957988113\n",
      "0.5081576509837866\n",
      "0.4856287707340383\n",
      "0.487419491735272\n",
      "0.5021078584123527\n",
      "0.510497515697602\n",
      "0.47474505921206406\n",
      "0.5064850484549323\n",
      "0.4961381307760945\n",
      "0.5102838956700746\n",
      "0.5045758483711206\n",
      "0.4899205274772169\n",
      "0.5078283088556828\n",
      "0.46620383865167125\n",
      "0.4907043087459575\n",
      "0.4861892258976094\n",
      "0.5216596673155995\n",
      "0.4945927110350387\n",
      "0.49225830869974535\n",
      "0.5181531290607434\n",
      "0.4596400505718696\n",
      "0.4916613937627654\n",
      "0.49794273492221824\n",
      "0.5020189503200181\n",
      "0.506836233431991\n",
      "0.4827245409719803\n",
      "0.503333148753256\n",
      "0.49718011335010603\n",
      "0.49826023128455904\n",
      "0.5096239678665877\n",
      "0.517665591392016\n",
      "0.49743925794338323\n",
      "0.5046244208857705\n",
      "0.5313371069081332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4922087349448726\n",
      "0.48926824687917\n",
      "0.4962105693785129\n",
      "0.5044451813684536\n",
      "0.5004957311959001\n",
      "0.5012201102001543\n",
      "0.5057924929652267\n",
      "0.5002719652136146\n",
      "0.5070998064691428\n",
      "0.5001070139129558\n",
      "0.516925264406301\n",
      "0.4968278177545135\n",
      "0.5153521786011594\n",
      "0.4889018272218839\n",
      "0.4943265719992231\n",
      "0.5015081878443456\n",
      "0.47125486282639123\n",
      "0.4915650086960878\n",
      "0.5050268135103626\n",
      "0.4911044770890458\n",
      "0.4976179869840427\n",
      "0.4803343852399332\n",
      "0.5065036754554862\n",
      "0.5088585386112963\n",
      "0.5066470443832325\n",
      "0.5087887448247069\n",
      "0.5237314581746664\n",
      "0.5117454273320116\n",
      "0.4930833896260128\n",
      "0.4909678378921612\n",
      "0.5056601551970327\n",
      "0.49463088905222796\n",
      "0.48549173065893714\n",
      "0.4742862979744297\n",
      "0.50815503160818\n",
      "0.48415969438334516\n",
      "0.4897016853472851\n",
      "0.49440387996590285\n",
      "0.5020264904350508\n",
      "0.5105563129298005\n",
      "0.4786237437602755\n",
      "0.5032229941314348\n",
      "0.497673792987608\n",
      "0.4858713011156688\n",
      "0.4883228172200191\n",
      "0.5000133929912309\n",
      "0.48441579867134504\n",
      "0.49652120790394655\n",
      "0.49553282913533486\n",
      "0.49956852639197796\n",
      "0.5069387656834025\n",
      "0.4972431303480505\n",
      "0.5066841579008906\n",
      "0.48473041857401333\n",
      "0.516190209210108\n",
      "0.46969756331272855\n",
      "0.5193717891671713\n",
      "0.49540699889389495\n",
      "0.495510011886905\n",
      "0.5344859885299883\n",
      "0.4900100521436807\n",
      "0.4955426421608081\n",
      "0.48700977178937516\n",
      "0.5056815753471123\n",
      "0.47975524797107383\n",
      "0.5038630369091724\n",
      "0.48312740050786496\n",
      "0.4998378387798823\n",
      "0.4862110975277512\n",
      "0.493486856973657\n",
      "0.49242376145617234\n",
      "0.4976161677254396\n",
      "0.4929879513242163\n",
      "0.4970892001985902\n",
      "0.4961563862332222\n",
      "0.5210482728953078\n",
      "0.525164191336836\n",
      "0.480177171628272\n",
      "0.49278077210983895\n",
      "0.5098086487067709\n",
      "0.5152281673966892\n",
      "0.502805393173112\n",
      "0.48976664362915584\n",
      "0.48363344800581676\n",
      "0.5018590421043501\n",
      "0.5163324337377683\n",
      "0.49177485902661666\n",
      "0.5037668032564653\n",
      "0.4934798621978989\n",
      "0.4870637548737837\n",
      "0.4976432045049402\n",
      "0.4855248966547021\n",
      "0.5053235232233947\n",
      "0.5110709924499801\n",
      "0.4755474710865885\n",
      "0.4858625734553153\n",
      "0.4854766832210714\n",
      "0.49503717972180394\n",
      "0.506690086652217\n",
      "0.49628988485403625\n",
      "0.49135726719314715\n",
      "0.4951331773398247\n",
      "0.5022668357078875\n",
      "0.4816626440002665\n",
      "0.5024512928988432\n",
      "0.46527202183195515\n",
      "0.4773462257642583\n",
      "0.5001078668829076\n",
      "0.48571271561971063\n",
      "0.5071204082549456\n",
      "0.495412963202056\n",
      "0.44073269325990005\n",
      "0.508175876765111\n",
      "0.5048411169004647\n",
      "0.5076673565298487\n",
      "0.5059792212732679\n",
      "0.4721654587231846\n",
      "0.5017329081001023\n",
      "0.5011875063405914\n",
      "0.5129702618313949\n",
      "0.4870010095919847\n",
      "0.4857373959733219\n",
      "0.507867786756132\n",
      "0.4838748197877275\n",
      "0.5209662307509186\n",
      "0.5104039354904039\n",
      "0.4947308486565303\n",
      "0.49606341584591435\n",
      "0.49529730613450484\n",
      "0.4716772112847503\n",
      "0.49092087031421416\n",
      "0.5071391388496347\n",
      "0.5062154046336818\n",
      "0.4784286260658069\n",
      "0.4987101737272269\n",
      "0.4984661753739547\n",
      "0.4937104324060802\n",
      "0.5019295255131188\n",
      "0.5109326656709404\n",
      "0.49954772565274297\n",
      "0.4954389346144737\n",
      "0.49747130247601584\n",
      "0.49300146323488103\n",
      "0.5080977956583713\n",
      "0.4892402891888376\n",
      "0.48662832863084826\n",
      "0.5074761813818396\n",
      "0.4877913163994094\n",
      "0.4827759678887034\n",
      "0.4946138299877807\n",
      "0.49890031253220285\n",
      "0.49128224325125036\n",
      "0.4793003949247127\n",
      "0.49671726183878845\n",
      "0.5108004292433492\n",
      "0.48964733600388044\n",
      "0.48276223404603563\n",
      "0.496318133240428\n",
      "0.5244601535929395\n",
      "0.5181147395145099\n",
      "0.5016343443468131\n",
      "0.5033826399687735\n",
      "0.4850881403202737\n",
      "0.5004833620850856\n",
      "0.4555954773890941\n",
      "0.507751798848941\n",
      "0.5099998878808882\n",
      "0.5057249371740594\n",
      "0.5150702434798047\n",
      "0.5043489249580361\n",
      "0.5016036118260688\n",
      "0.4733392869328822\n",
      "0.48184699731657094\n",
      "0.48738183602178015\n",
      "0.47081712849911267\n",
      "0.5169246618551225\n",
      "0.4999398582207711\n",
      "0.48693398838198926\n",
      "0.49718828938618315\n",
      "0.4917235774151943\n",
      "0.49224779799571294\n",
      "0.5025533562155782\n",
      "0.4925474328018597\n",
      "0.5049954260042203\n",
      "0.5047222288469561\n",
      "0.5107809942861408\n",
      "0.5112101124435867\n",
      "0.5138640943427688\n",
      "0.5152289721511214\n",
      "0.4872889178569904\n",
      "0.4798524628247956\n",
      "0.4936374286238686\n",
      "0.5053638195841385\n",
      "0.5063496101264771\n",
      "0.48905265956911137\n",
      "0.48915756652709114\n",
      "0.5193043919285467\n",
      "0.49037110685374924\n",
      "0.4765494520381409\n",
      "0.48617526534880373\n",
      "0.46110429073525977\n",
      "0.4858035514741367\n",
      "0.4976686500311518\n",
      "0.4991788662635377\n",
      "0.49005839255505207\n",
      "0.5018128722094085\n",
      "0.5056807878121511\n",
      "0.4883717286962868\n",
      "0.5096960240761781\n",
      "0.4910279512715462\n",
      "0.501094492569064\n",
      "0.5125441516403296\n",
      "0.49723868027546536\n",
      "0.497027463432741\n",
      "0.5026076899636841\n",
      "0.48381480520183995\n",
      "0.499410075944674\n",
      "0.49607252161022186\n",
      "0.5160295243890772\n",
      "0.48646296289480684\n",
      "0.48452766291767563\n",
      "0.5162748560101094\n",
      "0.49777910244568463\n",
      "0.515931756008261\n",
      "0.49977523989381706\n",
      "0.5041324501631805\n",
      "0.5063280697357989\n",
      "0.5078132036401942\n",
      "0.5084137104408728\n",
      "0.508666246301406\n",
      "0.5054049709623025\n",
      "0.500072280644512\n",
      "0.5064785899397359\n",
      "0.49745214244928015\n",
      "0.48598305107158146\n",
      "0.48437324193986436\n",
      "0.5002053395350434\n",
      "0.4948005976707035\n",
      "0.5096950246901651\n",
      "0.48625884932728997\n",
      "0.48616607436680254\n",
      "0.49192447328411076\n",
      "0.5284770974890539\n",
      "0.4989117837131791\n",
      "0.5051878787803169\n",
      "0.5095120289802009\n",
      "0.49316154474633694\n",
      "0.4935620608855532\n",
      "0.5097957053061781\n",
      "0.5076622555634249\n",
      "0.5096811511589808\n",
      "0.5065544931922503\n",
      "0.5087129210397621\n",
      "0.5126907643283664\n",
      "0.490916239692695\n",
      "0.4757378041488001\n",
      "0.5009340063485032\n",
      "0.49191278742556527\n",
      "0.5055240955173138\n",
      "0.5055546288060138\n",
      "0.5180839885396409\n",
      "0.48646711746124705\n",
      "0.506541216514321\n",
      "0.4921616459620561\n",
      "0.49664431881292825\n",
      "0.47836965257452113\n",
      "0.5070018276343267\n",
      "0.5077554592874658\n",
      "0.4965529127703045\n",
      "0.49650281234916493\n",
      "0.5118950534593955\n",
      "0.5195956182773983\n",
      "0.49086900993587507\n",
      "0.5136989145851947\n",
      "0.5024270819970601\n",
      "0.4920846379632152\n",
      "0.5019688038664365\n",
      "0.5044153114928132\n",
      "0.5105232042630509\n",
      "0.4938101046719941\n",
      "0.5081310930139111\n",
      "0.5029486340151176\n",
      "0.5089344246453301\n",
      "0.511276424758613\n",
      "0.49155158697348944\n",
      "0.4942476645543934\n",
      "0.5044758436035673\n",
      "0.5053444980627291\n",
      "0.49350458565436384\n",
      "0.4726300557915863\n",
      "0.5067991067130677\n",
      "0.4747418896710864\n",
      "0.5025242658749264\n",
      "0.49242504515186786\n",
      "0.4692571372564075\n",
      "0.5058743389656674\n",
      "0.4957465976785187\n",
      "0.5009819442121006\n",
      "0.48204507000982466\n",
      "0.4805279833035236\n",
      "0.48900206151168296\n",
      "0.496993804662016\n",
      "0.509157747153309\n",
      "0.4815573129796808\n",
      "0.47722739185394925\n",
      "0.48885624477205025\n",
      "0.4896651580377636\n",
      "0.49326922403369716\n",
      "0.4970823094483883\n",
      "0.4930327571008528\n",
      "0.4820191270417387\n",
      "0.49640298491734286\n",
      "0.5046052605167602\n",
      "0.5041636514353096\n",
      "0.5061958668274663\n",
      "0.5026495765971437\n",
      "0.49739961446364306\n",
      "0.5138266805779576\n",
      "0.5049202106907434\n",
      "0.49244516106843556\n",
      "0.5048414155076605\n",
      "0.49243852910312685\n",
      "0.5098409846022001\n",
      "0.49910732943750086\n",
      "0.5054733032241633\n",
      "0.48410143853252807\n",
      "0.5054583541302116\n",
      "0.4849123749182167\n",
      "0.48516154693733804\n",
      "0.47723916400817074\n",
      "0.5014154259939687\n",
      "0.4936689140424548\n",
      "0.48187916183646423\n",
      "0.48984895503366843\n",
      "0.4701681661100198\n",
      "0.49658826423916363\n",
      "0.491266499620027\n",
      "0.49924720775804776\n",
      "0.4873929905164791\n",
      "0.5026336160698832\n",
      "0.5044275398848167\n",
      "0.4887286140590916\n",
      "0.5120776017568479\n",
      "0.47540157799065336\n",
      "0.49902816424960766\n",
      "0.5149209790661975\n",
      "0.4931948113362315\n",
      "0.5254472354650119\n",
      "0.49696556090556643\n",
      "0.4819233557133823\n",
      "0.5172597986347588\n",
      "0.49915551750555476\n",
      "0.5064258554007149\n",
      "0.4780862074248385\n",
      "0.48307514741343194\n",
      "0.5043358744145815\n",
      "0.509423989804335\n",
      "0.5051659311540502\n",
      "0.5023688300610288\n",
      "0.4748440134210322\n",
      "0.48919368479223097\n",
      "0.5002522357233109\n",
      "0.5056247397379956\n",
      "0.5004011280502406\n",
      "0.4941174933866658\n",
      "0.5093918103512697\n",
      "0.4966914680595425\n",
      "0.5050721082143923\n",
      "0.5096018496928624\n",
      "0.5033874309694456\n",
      "0.4803682707874894\n",
      "0.5061650896001649\n",
      "0.49891919382678557\n",
      "0.5266936492422616\n",
      "0.4846544120588436\n",
      "0.5018475694514871\n",
      "0.49470967194477494\n",
      "0.46869276646685404\n",
      "0.5061680232839917\n",
      "0.5055526244281734\n",
      "0.5048951781615969\n",
      "0.5004980020543123\n",
      "0.5035152426648069\n",
      "0.5108289075620022\n",
      "0.5103307821371881\n",
      "0.49327531078030706\n",
      "0.5199821400685489\n",
      "0.5013540173036339\n",
      "0.48702048858422037\n",
      "0.4808604986121964\n",
      "0.5024221464516851\n",
      "0.5027853629728445\n",
      "0.5027068474846904\n",
      "0.49437134346918865\n",
      "0.49840523697409933\n",
      "0.510227517944534\n",
      "0.48897662348218585\n",
      "0.49519886664046786\n",
      "0.48328086381279434\n",
      "0.5027706565935617\n",
      "0.49479977830226407\n",
      "0.5073439572493387\n",
      "0.496476430312003\n",
      "0.49572196081251624\n",
      "0.5019335043820097\n",
      "0.48963600617426384\n",
      "0.48411072016401324\n",
      "0.50221512408867\n",
      "0.4940784732345894\n",
      "0.4994478546872609\n",
      "0.5055908109301522\n",
      "0.5162316332415282\n",
      "0.5104290998233265\n",
      "0.4993852805908863\n",
      "0.5054795930124247\n",
      "0.47604320688920176\n",
      "0.4902016617551766\n",
      "0.4851507836856072\n",
      "0.496175204039852\n",
      "0.49643210812014427\n",
      "0.4914751533521387\n",
      "0.5100558784125596\n",
      "0.4920517406932992\n",
      "0.5046364403259347\n",
      "0.5005664297486125\n",
      "0.4884107603262137\n",
      "0.5074756313111057\n",
      "0.49016989028291985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49459876987700613\n",
      "0.5025375189994047\n",
      "0.5064772462079915\n",
      "0.4817769450565175\n",
      "0.4890707103055926\n",
      "0.5078242536339145\n",
      "0.47973274885439776\n",
      "0.48333576091610836\n",
      "0.4954256306795969\n",
      "0.5174047399687837\n",
      "0.4860241561695991\n",
      "0.5019447925543877\n",
      "0.4972694286385812\n",
      "0.4856621616895756\n",
      "0.489654502668237\n",
      "0.49036326277157843\n",
      "0.5034401467950815\n",
      "0.4996578888831493\n",
      "0.4942198624280091\n",
      "0.4808466592811911\n",
      "0.49964673047589325\n",
      "0.48895670107605205\n",
      "0.4973798534079947\n",
      "0.48278866309120594\n",
      "0.48972865642701985\n",
      "0.5023014860441279\n",
      "0.4943578114078164\n",
      "0.500583147743834\n",
      "0.4903288601269466\n",
      "0.4980510864553646\n",
      "0.4956239977853443\n",
      "0.49365189427290707\n",
      "0.5092710307375284\n",
      "0.4949800608688025\n",
      "0.5150891283104627\n",
      "0.4696611470279071\n",
      "0.5023381909520099\n",
      "0.4861950711694126\n",
      "0.5393040231833647\n",
      "0.4782061016397771\n",
      "0.4854450549635487\n",
      "0.4796098563740981\n",
      "0.493188251225438\n",
      "0.5158412591218136\n",
      "0.4990869633205669\n",
      "0.5129029717369737\n",
      "0.4872170324632345\n",
      "0.478190775048409\n",
      "0.4953374067409004\n",
      "0.4920044669815032\n",
      "0.5042020509149278\n",
      "0.5096010717123768\n",
      "0.49400924078138264\n",
      "0.4863680148605603\n",
      "0.4865264002234667\n",
      "0.48672361254244834\n",
      "0.47763979739054796\n",
      "0.5196340414690067\n",
      "0.50053598785149\n",
      "0.5060599778105754\n",
      "0.5051819431502376\n",
      "0.5144784604407135\n",
      "0.5091407198499148\n",
      "0.4917589101810089\n",
      "0.48855584466086793\n",
      "0.5131618923959032\n",
      "0.5110849639404574\n",
      "0.4960364986827964\n",
      "0.4978172339372511\n",
      "0.510330580008421\n",
      "0.5090383009844286\n",
      "0.5047265110825824\n",
      "0.5221636759062408\n",
      "0.49943006352441727\n",
      "0.48914431553153437\n",
      "0.5185681301621666\n",
      "0.5008307600106779\n",
      "0.5095352565407438\n",
      "0.5047755968467428\n",
      "0.48530823144789703\n",
      "0.4966173403379306\n",
      "0.48628702579405547\n",
      "0.49587201577352386\n",
      "0.5013259539294344\n",
      "0.489410932428504\n",
      "0.505804150626651\n",
      "0.49378466351314976\n",
      "0.4936525600356921\n",
      "0.49293491264365435\n",
      "0.47077066383533744\n",
      "0.496933445538073\n",
      "0.47067331125131867\n",
      "0.4819737925305188\n",
      "0.49008221490476134\n",
      "0.5155196954680069\n",
      "0.4915107606377918\n",
      "0.4911677770946937\n",
      "0.5022893321814579\n",
      "0.5012188091611203\n",
      "0.4893839320928578\n",
      "0.4878036138923768\n",
      "0.5008391465032483\n",
      "0.5111277045867086\n",
      "0.5063333294984583\n",
      "0.4961759655956333\n",
      "0.49839606780352785\n",
      "0.4987415345283092\n",
      "0.5186843840423468\n",
      "0.49220744844511394\n",
      "0.5145487457873548\n",
      "0.5059096350215668\n",
      "0.5076956604588363\n",
      "0.5043251184278025\n",
      "0.5054659868850649\n",
      "0.5011264017004577\n",
      "0.5061022304906047\n",
      "0.5042393250243145\n",
      "0.49488267853151247\n",
      "0.49876083774145835\n",
      "0.5334693003103027\n",
      "0.5035641286639929\n",
      "0.519037247343428\n",
      "0.48472852027279745\n",
      "0.5119751001135785\n",
      "0.5063115708501821\n",
      "0.4913080975618326\n",
      "0.47232178378501194\n",
      "0.5084389897905929\n",
      "0.4733077319193631\n",
      "0.5057623377231302\n",
      "0.49117848207912096\n",
      "0.49799127035737667\n",
      "0.4962669307062607\n",
      "0.48612380190092686\n",
      "0.5023378963110631\n",
      "0.4925041241903266\n",
      "0.5546420261015418\n",
      "0.5086000142164522\n",
      "0.503370520934605\n",
      "0.5019787971690381\n",
      "0.4943570932098249\n",
      "0.4914812743655593\n",
      "0.4977701004932804\n",
      "0.5005821931083491\n",
      "0.51531910055435\n",
      "0.5127607585273511\n",
      "0.4850812098241439\n",
      "0.5089221690121057\n",
      "0.4792615569064746\n",
      "0.48037172228337277\n",
      "0.4851990304020025\n",
      "0.506722956650096\n",
      "0.4872351473252309\n",
      "0.4802608049027986\n",
      "0.5060459238457047\n",
      "0.4856487700227866\n",
      "0.5059379297177437\n",
      "0.4952547426569398\n",
      "0.47600223676564324\n",
      "0.5080709067857498\n",
      "0.5168647230815774\n",
      "0.5109853827930482\n",
      "0.5133151338733517\n",
      "0.5025543313685745\n",
      "0.49990532716315644\n",
      "0.5047313348168927\n",
      "0.5183598469385923\n",
      "0.4748073502028333\n",
      "0.4787028082429219\n",
      "0.4794462045076964\n",
      "0.508293615567157\n",
      "0.49017990913592324\n",
      "0.4927430659339512\n",
      "0.4900147655605141\n",
      "0.5103760124279473\n",
      "0.5053900315904265\n",
      "0.49457514600842717\n",
      "0.5108997802782665\n",
      "0.4992596090340046\n",
      "0.4872591145209408\n",
      "0.49471216814902824\n",
      "0.4904331445128714\n",
      "0.4915591905124875\n",
      "0.49914764711001475\n",
      "0.4964170129322402\n",
      "0.4932389586805383\n",
      "0.47531650679856813\n",
      "0.48341948753596353\n",
      "0.49644394430592675\n",
      "0.48285831204028634\n",
      "0.4860649640510303\n",
      "0.5016763052960476\n",
      "0.5092553690909284\n",
      "0.49428423608722577\n",
      "0.5008396039314545\n",
      "0.4891596601563741\n",
      "0.4836180469348562\n",
      "0.5035682561184884\n",
      "0.49207912181979435\n",
      "0.4846945926108541\n",
      "0.49565315192916254\n",
      "0.5177810892971029\n",
      "0.5114297339259709\n",
      "0.49720575885574714\n",
      "0.5117556950590294\n",
      "0.4898289397193179\n",
      "0.4812658123292709\n",
      "0.5000092283096229\n",
      "0.5100634119311749\n",
      "0.5034384234433176\n",
      "0.502930092595835\n",
      "0.4844193468199696\n",
      "0.47778154727138067\n",
      "0.4862926409067365\n",
      "0.49657553560946305\n",
      "0.5276729626251803\n",
      "0.4926282964032424\n",
      "0.490987771880233\n",
      "0.4955364461119075\n",
      "0.47454511080849904\n",
      "0.4942405183411021\n",
      "0.5077586980309711\n",
      "0.510618469458996\n",
      "0.5041935294602112\n",
      "0.4851257277948908\n",
      "0.51374223064715\n",
      "0.5003645435285908\n",
      "0.49656156147026326\n",
      "0.5004596177496498\n",
      "0.4855261023821418\n",
      "0.4965620388909817\n",
      "0.4885992291020199\n",
      "0.4926926335775415\n",
      "0.4838840368517495\n",
      "0.49723174513241\n",
      "0.5068549205562891\n",
      "0.4812795288749342\n",
      "0.4893654680583391\n",
      "0.5108520268019153\n",
      "0.5120965622778968\n",
      "0.533386995846105\n",
      "0.4900922924537819\n",
      "0.47791014933197523\n",
      "0.5045461598507894\n",
      "0.4975145277311218\n",
      "0.5131853521922219\n",
      "0.49291876057340855\n",
      "0.49796651026066385\n",
      "0.46976862527792446\n",
      "0.4975938495844029\n",
      "0.49955622063916416\n",
      "0.5117320377006161\n",
      "0.4966747568719735\n",
      "0.49936947129494913\n",
      "0.5042880930050385\n",
      "0.48712750457674286\n",
      "0.5080813269456547\n",
      "0.509404143417611\n",
      "0.49685959013313125\n",
      "0.49085203115573156\n",
      "0.4886272747765285\n",
      "0.49689438668713376\n",
      "0.5062371132123651\n",
      "0.4885900368632965\n",
      "0.5054044638107373\n",
      "0.5037106455420788\n",
      "0.4947412906296383\n",
      "0.4996590483185488\n",
      "0.5186528116871306\n",
      "0.49741140631678793\n",
      "0.49424651020531674\n",
      "0.5085374110762619\n",
      "0.49473359395219824\n",
      "0.5120572725675843\n",
      "0.4847287266846905\n",
      "0.5091007672561536\n",
      "0.5051360627434918\n",
      "0.5121414189946336\n",
      "0.47824170343967104\n",
      "0.4954678159828378\n",
      "0.525914460077217\n",
      "0.5202531071318918\n",
      "0.49572852305207604\n",
      "0.48297554827025474\n",
      "0.4789703045339621\n",
      "0.48821876818459536\n",
      "0.5083926512986511\n",
      "0.493004027796686\n",
      "CPU times: user 9h 53min 5s, sys: 2h 2min 34s, total: 11h 55min 40s\n",
      "Wall time: 2h 5min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(epoch, epoch+2000):\n",
    "    for i in range(1000):\n",
    "        l, _ = sess.run([hard_kl, opt], {phase:True})\n",
    "        if i % 30 == 0:\n",
    "            s = all_sum.eval({phase:True})\n",
    "            writer.add_summary(s, global_step=epoch*1000 + i)\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3e-05"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.assign(0.00003).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.169 0.065 0.055 0.064 0.071 0.055 0.06  0.061 0.062 0.065 0.063 0.058\n",
      "  0.063 0.064 0.056 0.063 0.068 0.062 0.055 0.054]]\n"
     ]
    }
   ],
   "source": [
    "ss = []\n",
    "for _ in range(40000):\n",
    "    s = shocks_hard.eval()[:,:,1].astype('float')\n",
    "    ss.append(s)\n",
    "ss = np.array(ss)\n",
    "print(ss.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9c23aa9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(2016-data.shape[1],2016)\n",
    "plt.plot(x, ss.mean(axis=0)[0][:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = []\n",
    "aa = []\n",
    "for _ in range(3000):\n",
    "    a = np.linalg.inv(PWalk.inverse_sigma.eval())\n",
    "    ss.append(np.sqrt(np.diag(a)))\n",
    "    aa.append(a)\n",
    "ss = np.array(ss)\n",
    "aa = np.array(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.mean(axis=0)[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ss, axis=0), np.std(ss, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.kdeplot(ss[:,1], ss[:,0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for _ in range(3000):\n",
    "    s = out.eval({phase:True})\n",
    "    samples.append(s)\n",
    "samples = np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 10\n",
    "sns.kdeplot(samples[:,t,2,0], samples[:,t,0,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 10\n",
    "# params[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(samples[:,t], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(samples[:,t], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors.kde import KernelDensity\n",
    "def score(s1, s2):\n",
    "    bw = 0.1\n",
    "    s1 = s1[:,np.newaxis]\n",
    "    s2 = s2[:,np.newaxis]\n",
    "    e1 = KernelDensity(bandwidth=bw).fit(s1)\n",
    "    e2 = KernelDensity(bandwidth=bw).fit(s2)\n",
    "    \n",
    "    e1e2 = e1.score(s1) - e2.score(s1)\n",
    "    e2e1 = e2.score(s2) - e1.score(s2)\n",
    "    dist = (e1e2/len(s1) + e2e1/len(s2))/2\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cdf(ts):\n",
    "    return lambda x: (ts <= x).mean()\n",
    "def score(s1,s2):\n",
    "    c1 = get_cdf(s1)\n",
    "    c2 = get_cdf(s2)\n",
    "\n",
    "    m = 0\n",
    "    for s in np.concatenate([s1, s2]):\n",
    "        r = np.abs(c1(s) - c2(s))\n",
    "        if r > m:\n",
    "            m = r\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = []\n",
    "for t1 in range(samples.shape[1] - 1):\n",
    "    np.random.seed(1234)\n",
    "    print(t1)\n",
    "    t2 = t1 + 1\n",
    "    s1 = samples[:,t1,0,0]\n",
    "    s2 = samples[:,t2,0,0]\n",
    "    ss = []\n",
    "    for _ in range(10):\n",
    "        s1_ = np.random.choice(s1, size=8000)\n",
    "        s2_ = np.random.choice(s2, size=8000)\n",
    "        m = score(s1_,s2_)\n",
    "        ss.append(m)\n",
    "    dists.append(ss)\n",
    "dists = np.array(dists).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDE + KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.tsplot(dists, ci=[50, 95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.tsplot(dists, ci=[50, 95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kolmogorov-Smirnov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.tsplot(dists, ci=[50, 95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.pow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (sys p)",
   "language": "python",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
